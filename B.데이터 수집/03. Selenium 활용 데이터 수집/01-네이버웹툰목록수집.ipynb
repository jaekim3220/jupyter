{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selenium 활용 데이터 수집 - 요일별 네이버 웹툰 목록"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "selenium\\\n",
    "웹 브라우저를 제어할 수 있는 파이썬 패키지"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chromedriver\\\n",
    "selenium과 Google Chrome 브라우저를 연결하는 프로그램\\\n",
    "파이썬 스스로 chromedriver를 내려받도록 하기 위해 chromedriver_autoinstaller  패키지가 필요함"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 셀리니움을 위한 패키지 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install --upgrade chromedriver_autoinstaller\n",
    "# ! pip install --upgrade selenium"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 추가 패키지 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChromeDriver 자동 설치 모듈\n",
    "import chromedriver_autoinstaller\n",
    "# Chrome 제어용 객체\n",
    "from selenium import webdriver\n",
    "# Chrome이 웹 페이지 로딩 완료할 때까지 N초간 대기\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from bs4 import BeautifulSoup\n",
    "from pandas import DataFrame\n",
    "# 파이썬 프로그램에 지정된 시간동안 랙을 거는 기능을 위해 사용\n",
    "import time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 크롬 브라우저 가동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크롬드라이버 자동 설치\n",
    "chromedriver_autoinstaller.install()\n",
    "\n",
    "# 크롬드라이버를 통해 크롬을 실행시킴\n",
    "# driver 객체는 Chrome 자체\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# 크롬브라우저가 준비될 때 까지 최대 5초씩 대기\n",
    "driver.implicitly_wait(5)\n",
    "# 이후 자동으로 chrome 브라우저 동작(이 브라우저는 건드리지 말것)\n",
    "# 이 chrome 브라우저에 정보를 기록,\n",
    "# 데이터를 크롤링 할 수 있도록 유도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요일별 네이버 웹툰에 접근하기 위한 변수값  생성\n",
    "# URL을 분석하여 얻어낸 값임(노가다 필요)\n",
    "params = ['mon', 'tue', 'wed', 'thu', 'fri', 'sat', 'sun', 'dailyPlus']\n",
    "\n",
    "# 네이버 웹툰의 주소 형식\n",
    "naverWebtoonUrl  = \"https://comic.naver.com/webtoon?tab={0}\"\n",
    "# naverWebtoonUrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수집된 데이터 결과가 누적될 빈 리스트 생성\n",
    "naverWebtoolData = []\n",
    "\n",
    "# 요일별 반복 생성\n",
    "\n",
    "for p in params:\n",
    "    # 특정 요일의 네이버 웹툰 페이지\n",
    "    url = naverWebtoonUrl.format(p)\n",
    "    # print(url)\n",
    "\n",
    "    # url을 크롬브라우저로 방문시킴\n",
    "    driver.get(url)\n",
    "    # 페이지가 이동할 때마다 시간을 설정해 로딩 시간 제공\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "    # 브라우저에 표시되는 전체 코드를 추출(bs4 객체로 변환)\n",
    "    soup = BeautifulSoup(driver.page_source)\n",
    "    # print(soup)\n",
    "\n",
    "    # 자식 연산자를 사용해 class 내부의 class\n",
    "    # 개발자 도구를 사용해 직접 class를 확인하며 추출\n",
    "    # class 추출 시 '.'을 붙일 것\n",
    "\n",
    "    # 웹툰이 표시되는 부분만 추출\n",
    "    webtoolList = soup.select(\".ContentList__content_list--q5KXY > .item\")\n",
    "    # print(webtoolList)\n",
    "\n",
    "    # 추출된 웹툰 목록 수 만큼 반복\n",
    "    for w in webtoolList:\n",
    "        # 포스터 URL\n",
    "        poster = w.select(\".Poster__image--d9XTI\")\n",
    "\n",
    "        # # 가져온 이미지가 존재, src 속성이 있는 경우\n",
    "        if poster and \"src\" in poster[0].attrs:\n",
    "            posterValue = poster[0].attrs['src']\n",
    "        else:\n",
    "            posterValue = None\n",
    "\n",
    "        # print(posterValue)\n",
    "\n",
    "\n",
    "        # 웹툰의 URL 추출(클릭 시 해당 웹툰 페이지 이동 url 포함 데이터)\n",
    "        url = w.select(\".Poster__link--sopnC\")\n",
    "\n",
    "        # 내부 url 진입은 공통 url을 제외 가능\n",
    "        # 외부에서 url 진입은 풀 url을 요구\n",
    "        if url and \"href\" in url[0].attrs:\n",
    "            urlValue = url[0].attrs[\"href\"]\n",
    "            if urlValue.find(\"https://comic.naver.com/\") == -1:\n",
    "                url = \"https://comic.naver.com/\"+urlValue\n",
    "        else:\n",
    "            urlValue=None\n",
    "        # print(urlValue)\n",
    "\n",
    "\n",
    "        # 웹툰 제목 추출\n",
    "        # 자식 연산자를 사용해 class 내부의 text class 추출\n",
    "        title = w.select(\".ContentTitle__title--e3qXt > .text\")\n",
    "\n",
    "        if title:\n",
    "            # strip을 사용해 필요없는 값 제거(공백 등)\n",
    "            titleValue = title[0].text.strip()\n",
    "        else:\n",
    "            # 제목이 없는 경우\n",
    "            titleValue : None\n",
    "\n",
    "        # print(titleValue)\n",
    "\n",
    "\n",
    "        # 작가 이름 추출\n",
    "        author = w.select(\".ContentAuthor__author--CTAAP\")\n",
    "        if author:\n",
    "            authorVlaue = author[0].text.strip()\n",
    "        else:\n",
    "            authorVlaue = None\n",
    "\n",
    "        # print(authorVlaue)\n",
    "\n",
    "\n",
    "        # 별점 추출\n",
    "        rating = w.select(\".Rating__star_area--dFzsb > .text\" )\n",
    "\n",
    "        if rating:\n",
    "            ratingValue = rating[0].text.strip()\n",
    "        else:\n",
    "            ratingValue = None\n",
    "\n",
    "        # print(ratingValue)\n",
    "\n",
    "        \n",
    "        # 추출 데이터 병합\n",
    "        resultDic = {\"요일\" : p, \"제목\" : titleValue, \"작가\" : authorVlaue, \"별점\" : ratingValue}\n",
    "        # print(resultDic)\n",
    "        naverWebtoolData.append(resultDic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naverWebtoolData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 엑셀로 저장\n",
    "df = DataFrame(naverWebtoolData)\n",
    "df.to_excel(\"요일별_네이버_웹툰.xlsx\", index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
