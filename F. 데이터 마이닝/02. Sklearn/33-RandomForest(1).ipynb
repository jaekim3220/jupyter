{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest(1)\n",
    "\n",
    "의사결정 트리를 사용하는 가장 대표적인 배깅 모델\n",
    "\n",
    "의사결정 트리의 단점(과적합이 자주 발생)을 보완하고 장점은 유지.\n",
    "\n",
    "최근 XGBoost, LightGBM, CatBoost와 함께 주목받는 알고리즘 중 하나.\n",
    "\n",
    "> 분류 : RandomForestClassifier\n",
    "> 회귀 : RandomForestRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #01. 패키지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sb\n",
    "from pandas import read_excel, DataFrame\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 데이터 불균형 해소를 위한 smpling 패키지\n",
    "from imblearn.under_sampling import RandomUnderSampler \n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #02. 데이터\n",
    "\n",
    "kaggle의 분류 예제 실습용 가상 데이터\n",
    "\n",
    "> https://www.kaggle.com/competitions/otto-group-product-classification-challenge/data\n",
    "\n",
    "| 필드이름 | 설명 |\n",
    "| -- | -- |\n",
    "| target | 타겟(종속)변수 `(Class_1~Class_9)` |\n",
    "| feat_1 ~ feat_93 | 설명(독립)변수 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 61878 entries, 0 to 61877\n",
      "Data columns (total 94 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   feat_1   61878 non-null  int64 \n",
      " 1   feat_2   61878 non-null  int64 \n",
      " 2   feat_3   61878 non-null  int64 \n",
      " 3   feat_4   61878 non-null  int64 \n",
      " 4   feat_5   61878 non-null  int64 \n",
      " 5   feat_6   61878 non-null  int64 \n",
      " 6   feat_7   61878 non-null  int64 \n",
      " 7   feat_8   61878 non-null  int64 \n",
      " 8   feat_9   61878 non-null  int64 \n",
      " 9   feat_10  61878 non-null  int64 \n",
      " 10  feat_11  61878 non-null  int64 \n",
      " 11  feat_12  61878 non-null  int64 \n",
      " 12  feat_13  61878 non-null  int64 \n",
      " 13  feat_14  61878 non-null  int64 \n",
      " 14  feat_15  61878 non-null  int64 \n",
      " 15  feat_16  61878 non-null  int64 \n",
      " 16  feat_17  61878 non-null  int64 \n",
      " 17  feat_18  61878 non-null  int64 \n",
      " 18  feat_19  61878 non-null  int64 \n",
      " 19  feat_20  61878 non-null  int64 \n",
      " 20  feat_21  61878 non-null  int64 \n",
      " 21  feat_22  61878 non-null  int64 \n",
      " 22  feat_23  61878 non-null  int64 \n",
      " 23  feat_24  61878 non-null  int64 \n",
      " 24  feat_25  61878 non-null  int64 \n",
      " 25  feat_26  61878 non-null  int64 \n",
      " 26  feat_27  61878 non-null  int64 \n",
      " 27  feat_28  61878 non-null  int64 \n",
      " 28  feat_29  61878 non-null  int64 \n",
      " 29  feat_30  61878 non-null  int64 \n",
      " 30  feat_31  61878 non-null  int64 \n",
      " 31  feat_32  61878 non-null  int64 \n",
      " 32  feat_33  61878 non-null  int64 \n",
      " 33  feat_34  61878 non-null  int64 \n",
      " 34  feat_35  61878 non-null  int64 \n",
      " 35  feat_36  61878 non-null  int64 \n",
      " 36  feat_37  61878 non-null  int64 \n",
      " 37  feat_38  61878 non-null  int64 \n",
      " 38  feat_39  61878 non-null  int64 \n",
      " 39  feat_40  61878 non-null  int64 \n",
      " 40  feat_41  61878 non-null  int64 \n",
      " 41  feat_42  61878 non-null  int64 \n",
      " 42  feat_43  61878 non-null  int64 \n",
      " 43  feat_44  61878 non-null  int64 \n",
      " 44  feat_45  61878 non-null  int64 \n",
      " 45  feat_46  61878 non-null  int64 \n",
      " 46  feat_47  61878 non-null  int64 \n",
      " 47  feat_48  61878 non-null  int64 \n",
      " 48  feat_49  61878 non-null  int64 \n",
      " 49  feat_50  61878 non-null  int64 \n",
      " 50  feat_51  61878 non-null  int64 \n",
      " 51  feat_52  61878 non-null  int64 \n",
      " 52  feat_53  61878 non-null  int64 \n",
      " 53  feat_54  61878 non-null  int64 \n",
      " 54  feat_55  61878 non-null  int64 \n",
      " 55  feat_56  61878 non-null  int64 \n",
      " 56  feat_57  61878 non-null  int64 \n",
      " 57  feat_58  61878 non-null  int64 \n",
      " 58  feat_59  61878 non-null  int64 \n",
      " 59  feat_60  61878 non-null  int64 \n",
      " 60  feat_61  61878 non-null  int64 \n",
      " 61  feat_62  61878 non-null  int64 \n",
      " 62  feat_63  61878 non-null  int64 \n",
      " 63  feat_64  61878 non-null  int64 \n",
      " 64  feat_65  61878 non-null  int64 \n",
      " 65  feat_66  61878 non-null  int64 \n",
      " 66  feat_67  61878 non-null  int64 \n",
      " 67  feat_68  61878 non-null  int64 \n",
      " 68  feat_69  61878 non-null  int64 \n",
      " 69  feat_70  61878 non-null  int64 \n",
      " 70  feat_71  61878 non-null  int64 \n",
      " 71  feat_72  61878 non-null  int64 \n",
      " 72  feat_73  61878 non-null  int64 \n",
      " 73  feat_74  61878 non-null  int64 \n",
      " 74  feat_75  61878 non-null  int64 \n",
      " 75  feat_76  61878 non-null  int64 \n",
      " 76  feat_77  61878 non-null  int64 \n",
      " 77  feat_78  61878 non-null  int64 \n",
      " 78  feat_79  61878 non-null  int64 \n",
      " 79  feat_80  61878 non-null  int64 \n",
      " 80  feat_81  61878 non-null  int64 \n",
      " 81  feat_82  61878 non-null  int64 \n",
      " 82  feat_83  61878 non-null  int64 \n",
      " 83  feat_84  61878 non-null  int64 \n",
      " 84  feat_85  61878 non-null  int64 \n",
      " 85  feat_86  61878 non-null  int64 \n",
      " 86  feat_87  61878 non-null  int64 \n",
      " 87  feat_88  61878 non-null  int64 \n",
      " 88  feat_89  61878 non-null  int64 \n",
      " 89  feat_90  61878 non-null  int64 \n",
      " 90  feat_91  61878 non-null  int64 \n",
      " 91  feat_92  61878 non-null  int64 \n",
      " 92  feat_93  61878 non-null  int64 \n",
      " 93  target   61878 non-null  object\n",
      "dtypes: int64(93), object(1)\n",
      "memory usage: 44.4+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>feat_10</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_85</th>\n",
       "      <th>feat_86</th>\n",
       "      <th>feat_87</th>\n",
       "      <th>feat_88</th>\n",
       "      <th>feat_89</th>\n",
       "      <th>feat_90</th>\n",
       "      <th>feat_91</th>\n",
       "      <th>feat_92</th>\n",
       "      <th>feat_93</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  feat_8  feat_9  \\\n",
       "0       1       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       1       0   \n",
       "2       0       0       0       0       0       0       0       1       0   \n",
       "3       1       0       0       1       6       1       5       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   feat_10  ...  feat_85  feat_86  feat_87  feat_88  feat_89  feat_90  \\\n",
       "0        0  ...        1        0        0        0        0        0   \n",
       "1        0  ...        0        0        0        0        0        0   \n",
       "2        0  ...        0        0        0        0        0        0   \n",
       "3        1  ...        0        1        2        0        0        0   \n",
       "4        0  ...        1        0        0        0        0        1   \n",
       "\n",
       "   feat_91  feat_92  feat_93   target  \n",
       "0        0        0        0  Class_1  \n",
       "1        0        0        0  Class_1  \n",
       "2        0        0        0  Class_1  \n",
       "3        0        0        0  Class_1  \n",
       "4        0        0        0  Class_1  \n",
       "\n",
       "[5 rows x 94 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origin = read_excel(\"https://data.hossam.kr/G02/otto_train.xlsx\")\n",
    "print(origin.info())\n",
    "origin.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #02. 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 타겟(종속)변수 라벨링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "Class_1     1929\n",
       "Class_2    16122\n",
       "Class_3     8004\n",
       "Class_4     2691\n",
       "Class_5     2739\n",
       "Class_6    14135\n",
       "Class_7     2839\n",
       "Class_8     8464\n",
       "Class_9     4955\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origin['target'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "1    16122\n",
       "5    14135\n",
       "7     8464\n",
       "2     8004\n",
       "8     4955\n",
       "6     2839\n",
       "4     2739\n",
       "3     2691\n",
       "0     1929\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origin['target'] = origin['target'].map({\n",
    "    \"Class_1\":0,\n",
    "    \"Class_2\":1,\n",
    "    \"Class_3\":2,\n",
    "    \"Class_4\":3,\n",
    "    \"Class_5\":4,\n",
    "    \"Class_6\":5,\n",
    "    \"Class_7\":6,\n",
    "    \"Class_8\":7,\n",
    "    \"Class_9\":8,\n",
    "})\n",
    "\n",
    "origin['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 제대로된 분류를 위해서는 데이터가 비슷한 비율로 존재해야 하는 만큼 데이터 불균형을 해결할 필요가 있음.\n",
    "\n",
    "즉, 전처리 과정에서 비슷한 규모로 데이터를 가질 수 있도록 샘플링 과정이 필요.\n",
    "\n",
    "사실 가장 좋은 해결 방법은 유의미한 데이터를 더 수집, 추가하는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 독립/종속변수 분리\n",
    "\n",
    "독립/종속변수 분리 후 데이터 불균형을 해소하는 것이 적합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['feat_1', 'feat_2', 'feat_3', 'feat_4', 'feat_5', 'feat_6', 'feat_7',\n",
       "       'feat_8', 'feat_9', 'feat_10', 'feat_11', 'feat_12', 'feat_13',\n",
       "       'feat_14', 'feat_15', 'feat_16', 'feat_17', 'feat_18', 'feat_19',\n",
       "       'feat_20', 'feat_21', 'feat_22', 'feat_23', 'feat_24', 'feat_25',\n",
       "       'feat_26', 'feat_27', 'feat_28', 'feat_29', 'feat_30', 'feat_31',\n",
       "       'feat_32', 'feat_33', 'feat_34', 'feat_35', 'feat_36', 'feat_37',\n",
       "       'feat_38', 'feat_39', 'feat_40', 'feat_41', 'feat_42', 'feat_43',\n",
       "       'feat_44', 'feat_45', 'feat_46', 'feat_47', 'feat_48', 'feat_49',\n",
       "       'feat_50', 'feat_51', 'feat_52', 'feat_53', 'feat_54', 'feat_55',\n",
       "       'feat_56', 'feat_57', 'feat_58', 'feat_59', 'feat_60', 'feat_61',\n",
       "       'feat_62', 'feat_63', 'feat_64', 'feat_65', 'feat_66', 'feat_67',\n",
       "       'feat_68', 'feat_69', 'feat_70', 'feat_71', 'feat_72', 'feat_73',\n",
       "       'feat_74', 'feat_75', 'feat_76', 'feat_77', 'feat_78', 'feat_79',\n",
       "       'feat_80', 'feat_81', 'feat_82', 'feat_83', 'feat_84', 'feat_85',\n",
       "       'feat_86', 'feat_87', 'feat_88', 'feat_89', 'feat_90', 'feat_91',\n",
       "       'feat_92', 'feat_93', 'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origin.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((61878, 93), (61878,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = origin.drop('target', axis=1)\n",
    "y = origin['target']\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 표준화\n",
    "\n",
    "> 여기서는 생략 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = StandardScaler()\n",
    "# std_x = scaler.fit_transform(x)\n",
    "# std_x[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 훈련/검증 데이터 분리\n",
    "\n",
    "1. 기존 코드\n",
    "2. Under Sampling 방식으로 데이터 불균형을 개선한 x, y 데이터 사용\n",
    "3. Under Sampling 방식으로 데이터 불균형을 개선한 x, y 데이터 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((43314, 93), (18564, 93), (43314,), (18564,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=777)\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 불균형 해소"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Under Sampling 방식 - Random Under Sampler\n",
    "\n",
    "많은 비율을 차지하는 다수 집단에서 일부만 샘플링하는 방식.\n",
    "\n",
    "소수 집단의 데이터가 어느 정도 확보 되었다고 여겨질 때, 다수 집단의 데이터를 줄여서 균형을 맞춘다.\n",
    "\n",
    "> 다수 집단의 유의미한 데이터를 손실할 수 있다는 단점이 존재.\n",
    "\n",
    "##### `sampling_strategy 파라미터`\n",
    "\n",
    "sampling_strategy : 2진 분류일 경우 실수로 설정 가능\n",
    "\n",
    "| 값 | 설명 |\n",
    "| -- | -- |\n",
    "| `majority` | `다수 클래스만` 다시 샘플링 |\n",
    "| `not majority` | `다수 아님` : 다수 클래스를 제외한 모든 클래스를 다시 샘플링 |\n",
    "| `not minority` | `소수 아님` : 소수 클래스를 제외한 모든 클래스를 다시 샘플링 |\n",
    "| `all` | `모든 클래스`를 다시 샘플링 |\n",
    "| `auto` | 자동 처리 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47685, 93) (47685,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "target\n",
       "0     1929\n",
       "1     1929\n",
       "2     8004\n",
       "3     2691\n",
       "4     2739\n",
       "5    14135\n",
       "6     2839\n",
       "7     8464\n",
       "8     4955\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 생성\n",
    "undersampler = RandomUnderSampler(sampling_strategy='majority', random_state=777)\n",
    "# 학습 진행\n",
    "# 독립변수를 표준화 했다면 표준화한 독립변수를 삽입\n",
    "x_under, y_under = undersampler.fit_resample(x,y)\n",
    "print(x_under.shape, y_under.shape)\n",
    "\n",
    "# Under Sampling 결과 확인\n",
    "y_under.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Over Sampling 방식 - Random Over Sampler\n",
    "\n",
    "소수 집단에서 복원 추출을 수행하는 방식.\n",
    "\n",
    "Under Sampling처럼 데이터 중 일부를 취하는 것은 아니기 때문에 데이터 손실은 발생하지 않지만, 동일한 데이터를 여러 번 학습 데이터에 포함시키므로 학습 정확도는 높지만 과적합 리스크가 존재.\n",
    "\n",
    "##### `sampling_strategy 파라미터`\n",
    "\n",
    "sampling_strategy : 2진 분류일 경우 실수로 설정 가능\n",
    "\n",
    "| 값 | 설명 |\n",
    "| -- | -- |\n",
    "| `minority` | `소수 클래스만` 다시 샘플링 |\n",
    "| `not majority` | `다수 아님` : 다수 클래스를 제외한 모든 클래스를 다시 샘플링 |\n",
    "| `not minority` | `소수 아님` : 소수 클래스를 제외한 모든 클래스를 다시 샘플링 |\n",
    "| `all` | `모든 클래스`를 다시 샘플링 |\n",
    "| `auto` | 자동 처리 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76071, 93) (76071,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    16122\n",
       "1    16122\n",
       "2     8004\n",
       "3     2691\n",
       "4     2739\n",
       "5    14135\n",
       "6     2839\n",
       "7     8464\n",
       "8     4955\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 생성\n",
    "oversampler = RandomOverSampler(sampling_strategy='minority', random_state=777)\n",
    "# 학습 진행\n",
    "x_over, y_over = oversampler.fit_resample(x,y)\n",
    "print(x_over.shape, y_over.shape)\n",
    "\n",
    "# Over Sampling 결과 확인\n",
    "y_over.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Over Sampling - SMOTE\n",
    "\n",
    "소수 집단의 데이터를 바탕으로 새로운 데이터를 생성.\n",
    "\n",
    "단순히 소수 집단의 데이터를 복원 추출하는 것이 아니라 소수 집단 데이터를 분석해 어떤 특징이 있는지 살피고 그와 유사한 패턴을 가지는 가짜 데이터를 생성.\n",
    "\n",
    "##### `sampling_strategy 파라미터`\n",
    "\n",
    "sampling_strategy : 2진 분류일 경우 실수로 설정 가능\n",
    "\n",
    "| 값 | 설명 |\n",
    "| -- | -- |\n",
    "| `minority` | `소수 클래스만` 다시 샘플링 |\n",
    "| `not majority` | `다수 아님` : 다수 클래스를 제외한 모든 클래스를 다시 샘플링 |\n",
    "| `not minority` | `소수 아님` : 소수 클래스를 제외한 모든 클래스를 다시 샘플링 |\n",
    "| `all` | `모든 클래스`를 다시 샘플링 |\n",
    "| `auto` | 자동 처리 |\n",
    "\n",
    "혹은 실수 타입으로 설정할 경우 샘플 수의 비율을 의미\n",
    "\n",
    "##### `k_neighbors 파라미터 (int)`\n",
    "\n",
    "합성 샘플을 생성하는데 사용할 샘플의 가장 가까운 이웃 수 (기본값=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76071, 93) (76071,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    16122\n",
       "1    16122\n",
       "2     8004\n",
       "3     2691\n",
       "4     2739\n",
       "5    14135\n",
       "6     2839\n",
       "7     8464\n",
       "8     4955\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 생성\n",
    "smote_sampler = SMOTE(sampling_strategy='minority', random_state=777)\n",
    "# 학습 진행\n",
    "x_sm, y_sm = smote_sampler.fit_resample(x,y)\n",
    "print(x_sm.shape, y_sm.shape)\n",
    "\n",
    "# Over Sampling 결과 확인\n",
    "y_sm.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #03. 랜덤 포레스트 모델 적합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단일 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE의 훈련 정확도 : 0.9999342719301705\n",
      "테스트 정확도 : 0.9999461322990735\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "# rfc = RandomForestClassifier(n_estimators=20, max_depth=5, random_state=777)\n",
    "# rfc = RandomForestClassifier(n_estimators=50, max_depth=30, random_state=777)\n",
    "# rfc = RandomForestClassifier(n_estimators=100, max_depth=50, random_state=777)\n",
    "rfc = RandomForestClassifier(n_estimators=100, max_depth=100, random_state=777)\n",
    "\n",
    "# # 학습(원본 데이터)\n",
    "# rfc.fit(x_train, y_train)\n",
    "# print(f\"원본 데이터의 훈련 정확도 : {rfc.score(x_train, y_train)}\")\n",
    "\n",
    "# # 학습(언더샘플링 데이터)\n",
    "# rfc.fit(x_under, y_under)\n",
    "# print(f\"언더샘플링의 훈련 정확도 : {rfc.score(x_train, y_train)}\")\n",
    "\n",
    "# # 학습(오버샘플링 데이터)\n",
    "# rfc.fit(x_over, y_over)\n",
    "# print(f\"오버샘플링의 훈련 정확도 : {rfc.score(x_over, y_over)}\")\n",
    "\n",
    "# 학습(SMOTE 데이터)\n",
    "rfc.fit(x_sm, y_sm)\n",
    "print(f\"SMOTE의 훈련 정확도 : {rfc.score(x_sm, y_sm)}\")\n",
    "\n",
    "# 테스트 정확도\n",
    "print(f\"테스트 정확도 : {rfc.score(x_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 모델 생성 단계에서 n_estimators, max_depth를 높이면 시간은 걸리지만 성능을 향상 시킬 가능성이 있음.\n",
    "\n",
    "100% 성능 향상은 기대하기 어려운 만큼 sampling이 필요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 하이퍼 파라미터 튜닝\n",
    "\n",
    "> GridSearchCV\n",
    "\n",
    "`cv` : 쪼개는 단위\n",
    "\n",
    "`n_jobs` : 실행할 병렬 작업의 수. CPU의 프로세스 수만큼 설정 가능. -1은 모든 프로세서를 사용함을 의미."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "rfc = RandomForestClassifier(random_state=777)\n",
    "\n",
    "# 사용할 파라미터 설정\n",
    "params = {\n",
    "    'random_state':[20,50,100,100],\n",
    "    \"max_depth\":[5,30,50,100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적의 하이퍼 파라미터 : {'max_depth': 100, 'random_state': 50}\n",
      "최적 훈련 정확도 : 0.8018424335770569\n",
      "최대 검증 정확도 : 0.8044602456367163\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>random_state</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>0.801842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.800642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.800642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>0.800619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>0.799741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>0.799741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>0.799718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.799372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>0.796024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>0.796024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>0.795216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>0.794501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.616637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>0.609249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.604077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.604077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  random_state  mean_test_score\n",
       "13        100            50         0.801842\n",
       "14        100           100         0.800642\n",
       "15        100           100         0.800642\n",
       "8          50            20         0.800619\n",
       "10         50           100         0.799741\n",
       "11         50           100         0.799741\n",
       "9          50            50         0.799718\n",
       "12        100            20         0.799372\n",
       "6          30           100         0.796024\n",
       "7          30           100         0.796024\n",
       "5          30            50         0.795216\n",
       "4          30            20         0.794501\n",
       "0           5            20         0.616637\n",
       "1           5            50         0.609249\n",
       "2           5           100         0.604077\n",
       "3           5           100         0.604077"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 생성\n",
    "grid = GridSearchCV(rfc, param_grid=params, cv=5, n_jobs=-1)\n",
    "# 학습\n",
    "grid.fit(x_train, y_train)\n",
    "\n",
    "print(\"최적의 하이퍼 파라미터 :\",grid.best_params_)\n",
    "print(\"최적 훈련 정확도 :\",grid.best_score_)\n",
    "\n",
    "# 예측 값\n",
    "y_pred = grid.best_estimator_.predict(x_test)\n",
    "print(\"최대 검증 정확도 :\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# 학습 결과 시각화\n",
    "result_df = DataFrame(grid.cv_results_['params'])\n",
    "# 평균 값 도출\n",
    "result_df['mean_test_score'] = grid.cv_results_['mean_test_score']\n",
    "# 정렬\n",
    "result_df.sort_values(by='mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
