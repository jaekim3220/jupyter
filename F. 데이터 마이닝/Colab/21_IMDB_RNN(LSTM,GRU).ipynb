{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVf-hWMbw9u8"
      },
      "source": [
        "# IMDB RNN, (LSTM, GRU)\n",
        "\n",
        "RNN은 순서와 맥락을 고려하지는 않음\n",
        "-> 일치하는 단어가 얼마나 있는가를 확인\n",
        "\n",
        "## #01. 텍스트 분석 알고리즘\n",
        "\n",
        "### 1. 텍스트 분석을 위해 개선된 알고리즘의 종류\n",
        "\n",
        "#### RNN\n",
        "\n",
        "- Embedding층은 단순하게 데이터의 표현을 학습하여 데이터 사전을 구축하는 것\n",
        "- 하지만 유사한 의미의 단어를 비슷한 공간에 매핑할 수 있지만, 시퀀스 데이터의 중요한 특성인 순서와 맥락까지 고려한 것은 아니다.\n",
        "- 순환 신경망은 이 문제를 해결하기 위해 고안된 층\n",
        "- 완전연결층, 컨볼루션 신경망의 반대되는 개념.\n",
        "- 완전연결층과 컨볼루션 신경망은 피드 포워드 네트워크(feed-forward network)라고 표현\n",
        "- 피드 포워드 네트워크는 신경망이 가지는 모든 출력값이 마지막층인 출력층을 향한다.\n",
        "- 하지만 순환 신경망은 각 층의 결과값이 출력층을 향하면서도 동시에 현재 층의 다음 계산에 사용된다.\n",
        "\n",
        "#### LSTM\n",
        "\n",
        "- RNN의 그래디언트 손실문제를 보완한 방법\n",
        "- 정보를 여러 시점에 걸쳐 나르는 장치(‘Cell state’)가 추가되었다.\n",
        "- 이로 인해 그래디언트를 보존할 수 있어 그래디언트 손실 문제가 발생하지 않도록 도와준다.\n",
        "\n",
        "#### GRU\n",
        "\n",
        "- 게이트 메커니즘이 적용된 RNN의 일종으로 LSTM에서 영감을 받았으며 더 간략한 구조를 갖는다.\n",
        "- 한국인 조경현 박사님이 제안한 방법\n",
        "\n",
        "### 2. 텍스트 분석 알고리즘 적용하기\n",
        "\n",
        "전체 소스코드는 지금까지의 예제들과 동일하게 진행된다.\n",
        "\n",
        "```\n",
        "💡 패키지 준비 → 데이터셋 준비 → 데이터 전처리 → 탐색적 데이터 분석(문자열 토큰화, 데이터를 동일한 길이로 맞추기) → 데이터 셋 분할 → 모델 개발(정의+학습) → 학습 결과 평가 → 학습결과 적용\n",
        "```\n",
        "\n",
        "이 과정에서 학습 모델을 정의하는 부분에서 적용할 알고리즘만 변경하면 되기 때문에 여기서는 RNN을 먼저 적용해 본 후, 학습 모델을 LSTM과 GRU로 각각 변경하여 다시 학습을 수행해 보도록 한다.\n",
        "\n",
        "학습 시간이 매우 오래 걸리는 예제이므로 가급적 GPU가 탑재된 컴퓨터에서 실습하는 것이 좋다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xtjv8l7oxGx6"
      },
      "source": [
        "## #02. 패키지 준비하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8wn-c3Av3Yb"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "sys.path.append(\"/content/drive/MyDrive/DLMLJUPYTER\")\n",
        "import helper_colab\n",
        "from pandas import DataFrame\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Flatten, SimpleRNN # LSTM, GRU\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.datasets import imdb\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZG-OhsGxavG"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwbWLfPDzBwu"
      },
      "source": [
        "## #03. 데이터 준비"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMJ5_7e9y-d9",
        "outputId": "e6475e2e-710c-48e3-8b3c-47a7e7cb5cae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 1s 0us/step\n",
            "훈련 데이터 (25000,) 레이블 (25000,)\n",
            "훈련 데이터 (25000,) 레이블 (25000,)\n"
          ]
        }
      ],
      "source": [
        "# 예제 데이터\n",
        "num_words = 10000\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words = num_words)\n",
        "print(f\"훈련 데이터 {x_train.shape} 레이블 {y_train.shape}\")\n",
        "print(f\"훈련 데이터 {x_test.shape} 레이블 {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQQmWjkEzZXT"
      },
      "source": [
        "## #04. 데이터 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fZx1QF-zaeN"
      },
      "source": [
        "### 1. 데이터를 동일한 길이로 맞추기 (padding)\n",
        "\n",
        "Embedding층을 사용하기 위해서는 시퀀스 데이터(여기서는 문장을 나타냅니다)의 길이가 전부 동일해야 한다.\n",
        "\n",
        "길이를 맞추기 위해 pad_sequences() 함수 사용\n",
        "\n",
        "- 데이터가 지정해준 길이보다 짧은 경우 0으로 채워 넣으며, 긴 경우는 잘라낸다.\n",
        "- 단어의 뒤에 패딩을 추가하고 싶다면, padding 인자를 post로 지정한다.\n",
        "\n",
        "> Embedding(임베딩)은 문장의 길이를 동일하게 맞추는 것\n",
        "\n",
        "padding에는 pre(앞에 0)와 post(뒤에 0)가 존재\n",
        "\n",
        "- pre-padding일 경우에는 앞단에 0이 채워져 마지막 단어로 제로 패딩이 입력으로 들어가는 일 없이 올바른 시퀀스 모델링이 진행\n",
        "- post-padding일 경우에는 뒷단에 0이 채워져 마지막 단어로 제로 패딩이 입력으로 사용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_wMbxuvzXNS",
        "outputId": "81922a98-25e4-42b0-e0ad-a3fce8a4a21f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "padding 이전 : 218 189\n",
            "padding 이후 : 500 500\n"
          ]
        }
      ],
      "source": [
        "# 최대 문장 길이\n",
        "max_len = 500\n",
        "\n",
        "print(\"padding 이전 :\", len(x_train[0]), len(x_train[1]))\n",
        "\n",
        "pad_x_train = pad_sequences(x_train, maxlen=max_len, padding='pre')\n",
        "pad_x_test = pad_sequences(x_test, maxlen=max_len, padding='pre')\n",
        "\n",
        "#  pre-padding으로 원래 단어의 앞에 '지정해준 단어의 길이 – 원래 단어의 길이' (500 –218)만큼 0이 추가된 것을 볼 수 있다.\n",
        "print('padding 이후 :', len(pad_x_train[0]), len(pad_x_train[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZ6QQQhS0Hsq"
      },
      "source": [
        "#### pre-padding 결과 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEOV1BOUz5Xe",
        "outputId": "5386d561-b9a9-4bfe-dfff-4dd8cf1d2e70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    1   14   22   16   43  530  973 1622 1385   65  458 4468\n",
            "   66 3941    4  173   36  256    5   25  100   43  838  112   50  670\n",
            "    2    9   35  480  284    5  150    4  172  112  167    2  336  385\n",
            "   39    4  172 4536 1111   17  546   38   13  447    4  192   50   16\n",
            "    6  147 2025   19   14   22    4 1920 4613  469    4   22   71   87\n",
            "   12   16   43  530   38   76   15   13 1247    4   22   17  515   17\n",
            "   12   16  626   18    2    5   62  386   12    8  316    8  106    5\n",
            "    4 2223 5244   16  480   66 3785   33    4  130   12   16   38  619\n",
            "    5   25  124   51   36  135   48   25 1415   33    6   22   12  215\n",
            "   28   77   52    5   14  407   16   82    2    8    4  107  117 5952\n",
            "   15  256    4    2    7 3766    5  723   36   71   43  530  476   26\n",
            "  400  317   46    7    4    2 1029   13  104   88    4  381   15  297\n",
            "   98   32 2071   56   26  141    6  194 7486   18    4  226   22   21\n",
            "  134  476   26  480    5  144   30 5535   18   51   36   28  224   92\n",
            "   25  104    4  226   65   16   38 1334   88   12   16  283    5   16\n",
            " 4472  113  103   32   15   16 5345   19  178   32]\n"
          ]
        }
      ],
      "source": [
        "print(pad_x_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhfY-9sX0E0c",
        "outputId": "21b3140a-1a4e-4030-8262-bdf03cad5ec8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    1  194 1153  194 8255   78  228    5    6 1463 4369\n",
            " 5012  134   26    4  715    8  118 1634   14  394   20   13  119  954\n",
            "  189  102    5  207  110 3103   21   14   69  188    8   30   23    7\n",
            "    4  249  126   93    4  114    9 2300 1523    5  647    4  116    9\n",
            "   35 8163    4  229    9  340 1322    4  118    9    4  130 4901   19\n",
            "    4 1002    5   89   29  952   46   37    4  455    9   45   43   38\n",
            " 1543 1905  398    4 1649   26 6853    5  163   11 3215    2    4 1153\n",
            "    9  194  775    7 8255    2  349 2637  148  605    2 8003   15  123\n",
            "  125   68    2 6853   15  349  165 4362   98    5    4  228    9   43\n",
            "    2 1157   15  299  120    5  120  174   11  220  175  136   50    9\n",
            " 4373  228 8255    5    2  656  245 2350    5    4 9837  131  152  491\n",
            "   18    2   32 7464 1212   14    9    6  371   78   22  625   64 1382\n",
            "    9    8  168  145   23    4 1690   15   16    4 1355    5   28    6\n",
            "   52  154  462   33   89   78  285   16  145   95]\n"
          ]
        }
      ],
      "source": [
        "print(pad_x_train[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vk2y_Ozz0eUd"
      },
      "source": [
        "## #04. 탐색적 데이터 분석\n",
        "\n",
        "> 실제로는 ***탐색적 데이터분석***을 통해 긍정/부정의 비율이 동일한지 확인 후 모델을 개발하고 학습을 진행. 이 과정을 건너뛰면 모델 생성, 학습이 제대로 되지 않음.\n",
        "\n",
        "여기서는 동일한 비율로 나눈 예제 데이터를 사용하기 때문에 생략."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDuT5iKP0NOr"
      },
      "source": [
        "## #05. 데이터 셋 분할하기\n",
        "\n",
        "이미 데이터셋이 훈련데이터와 검증데이터로 분리되어 있기 때문에 별도의 분할 작업을 수행할 필요는 없다.\n",
        "\n",
        "> 실제로는 **탐색적 데이터분석** 과정에서 긍정/부정의 비율이 동일한지 확인 후 모델을 개발, 학습을 진행. 이 과정을 건너뛰면 모델 생성, 학습이 제대로 되지 않음."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzCSlARy0kIj"
      },
      "source": [
        "## #06. 모델 개발"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owpJaXfF0ldu"
      },
      "source": [
        "### 모델 정의 (RNN)\n",
        "\n",
        "return_sequences 파라미터가 True로 지정되면 모든 학습 시점의 은닉 상태를 출력해 준다. False인 경우는 마지막 시점의 은닉 상태만 출력한다. (기본값=False)\n",
        "\n",
        "dropout은 지정된 비율만큼 학습을 건너뛰게 하는 파라미터. 이 파라미터를 사용하게 되면 과거 학습정보를 잃어버릴 확률이 높아지고 그에 따라 모델 성능이 나빠질 가능성이 있다.\n",
        "\n",
        ">dropout은 무작위로 건너뛰는 비율로 학습 속도는 향상되지만 과거 학습 정보를 잃어버릴 확률이 높아져 모델의 성능 저하가 발생할 수 있음.\n",
        "\n",
        "recurrent_dropout(순환드롭아웃)은 과거 학습정보를 잃어버리는 문제를 해결하기 위해 적용하는 옵션.\n",
        "- --------------------\n",
        "\n",
        "> Embedding층은 모델의 첫 번째 층으로만 사용할 수 있으며, 주로 순환 신경망과 연결하여 사용.\n",
        "\n",
        "(`Conv2D 적용 [-> BatchNormalization층 적용] -> MaxPool2D 적용 [-> Dropout]`)의 과정을 n번 반복 -> Flatten 레이어 추가 -> Dense층 n개 추가\n",
        "\n",
        "- **Conv2D 층**\n",
        "    - 영상이나 이미지의 특징을 확인하기 위한 함수\n",
        "    - `filters`: 필터(커널)의 개수\n",
        "    - `kernel_size`: 필터의 크기\n",
        "    - `strides`: 필터의 이동 간격\n",
        "    - `padding`: valid(패딩 없음), same(인풋과 아웃풋이 같도록 패딩)\n",
        "    - `activation`: 활성화 함수\n",
        "    - `input_shape`: 첫 레이어에 인풋으로 들어오는 크기\n",
        "\n",
        "- **BatchNormalization (배치정규화)**\n",
        "    - 신경망 입력데이터를 평균 0, 분산 1로 정규화해서 학습이 잘 이루어지도록 하는 방법\n",
        "    - BatchNormalization 층에서 정규화를 수행하므로 별도의 정규화를 적용할 필요가 없다.\n",
        "    - 만약 이 층을 적용하지 않는다면 학습 전에 별도의 정규화를 수행하는 것이 좋다.\n",
        "\n",
        "- **MaxPool2D**\n",
        "    - 컨볼루션 레이어의 출력 이미지에서 주요값만 뽑아 크기가 작은 출력 영상을 만든다.\n",
        "    - `pool_size`: 축소시킬 필터의 크기(비율)\n",
        "    - `strides`: 필터의 이동 간격. 기본값으로 pool_size를 갖는다.\n",
        "    - 일반적으로 strides는 pool_size와 동일하게 적용되므로 생략하는 편.\n",
        "\n",
        "- --------------------\n",
        " > filter가 클수록, kernel_size가 작을 수록 모델이 성능이 개선됨.\n",
        " 단, 학습 시간도 오래 걸림.\n",
        "\n",
        "> activation : 다중분류 = softmax, unit 10, 이진분류 = sigmoid, unit 1/0 - 주로 `relu`\n",
        "\n",
        "> loss : 다중분류 = categorical_crossentropy, 이진분류 = binary_crossentropy\n",
        "\n",
        "> Sequential : 모델을 하나 하나 차례로 집어 넣는다\n",
        "\n",
        "> Dense : 완전 연결 층\n",
        "\n",
        "> optimizer : 경사하강법 변화 버전(sgd, adam 등등)\n",
        "\n",
        "> metrics : 평가지표(학습 판단 기준) mse, mae, acc 등"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJFWFLoE0DBL",
        "outputId": "9c4df79e-f4df-40fa-db3d-ddee2e09064c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 500, 32)           320000    \n",
            "                                                                 \n",
            " simple_rnn (SimpleRNN)      (None, 500, 32)           2080      \n",
            "                                                                 \n",
            " simple_rnn_1 (SimpleRNN)    (None, 16)                784       \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 322881 (1.23 MB)\n",
            "Trainable params: 322881 (1.23 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(input_dim = num_words, output_dim = 32, input_length = max_len))\n",
        "model.add(SimpleRNN(32, return_sequences=True, dropout=0.15, recurrent_dropout=0.15))\n",
        "model.add(SimpleRNN(16))\n",
        "model.add(Dense(1, activation='sigmoid'))   #이진분류 = sigmoid\n",
        "\n",
        "# 결국은 긍정, 부정을 분류 하는 문제이므로 이진분류에 해당한다.\n",
        "model.compile(optimizer='adam',loss = 'binary_crossentropy', metrics = ['acc'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMctDHOh1YYq"
      },
      "source": [
        "### 학습하기\n",
        "\n",
        "- epochs는 많아도 크게 상관이 없음(단, 너무 크면 오래 걸리고 오차가 증가)\n",
        "    - callback을 사용해 모델의 학습 방향, 저장 시점, 학습 정지 시점 등에 관한 상황을 모니터링\n",
        "    - EarlyStopping 콜백과 같이 patience 인자를 지정하여, 지정된 기간 동안 `평가지표에서 성능 향상이 일어나지 않으면 학습률을 조정하는 콜백`\n",
        "    - ReduceLROnPlateau EarlyStopping 콜백과 같이 patience 인자를 지정하여, 지정된 기간 동안 `평가지표에서 성능 향상이 일어나지 않으면 학습률을 조정하는 콜백`\n",
        "    - ModelCheckpoint 지정한 평가지표를 기준으로 가장 뛰어난 성능을 보여주는 모델을 저장 할 때 사용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 587
        },
        "id": "xDz2Sffs1V1t",
        "outputId": "6c2d61af-bfe2-4c0f-c385-245a24f36c3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "782/782 [==============================] - 1192s 2s/step - loss: 0.3681 - acc: 0.8472 - val_loss: 0.4292 - val_acc: 0.8082 - lr: 0.0010\n",
            "Epoch 2/500\n",
            "782/782 [==============================] - 1101s 1s/step - loss: 0.3691 - acc: 0.8478 - val_loss: 0.4690 - val_acc: 0.7671 - lr: 0.0010\n",
            "Epoch 3/500\n",
            "103/782 [==>...........................] - ETA: 14:50 - loss: 0.4828 - acc: 0.7715"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1740\u001b[0m                         ):\n\u001b[1;32m   1741\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1742\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1743\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1744\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    855\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m       (concrete_function,\n\u001b[1;32m    147\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    149\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1347\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1348\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1349\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_call_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1350\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1457\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1458\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "  3/782 [..............................] - ETA: 13:52 - loss: 0.4301 - acc: 0.8125"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "result = model.fit(pad_x_train, y_train, epochs=500, validation_data=(pad_x_test, y_test), callbacks = [\n",
        "    EarlyStopping(monitor = 'val_loss', patience=5, verbose = 1),\n",
        "    ReduceLROnPlateau(monitor= \"val_loss\", patience=3, factor = 0.5, min_lr=0.0001, verbose=1)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKjKXjC_1fop"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}