import sys
import numpy as np
import seaborn as sb
from pca import pca
from math import sqrt
from tabulate import tabulate
from matplotlib import pyplot as plt

from pandas import DataFrame, MultiIndex, concat, DatetimeIndex, Series

from scipy import stats #í™•ë¥  ë¶„í¬, í†µê³„ ë¶„ì„, ì‹ í˜¸ ì²˜ë¦¬, ìµœì í™”, ì„ í˜• ëŒ€ìˆ˜ ë“±ì˜ ë‹¤ì–‘í•œ ê¸°ëŠ¥ì„ í¬í•¨
from scipy.stats import t, pearsonr, spearmanr
from scipy.stats import shapiro, normaltest, ks_2samp, bartlett, fligner, levene, chi2_contingency

from statsmodels.formula.api import ols, logit
from statsmodels.tsa.stattools import adfuller  # adfullerë¥¼ ì‚¬ìš©í•´ ë°ì´í„°ê°€ ì •ìƒì„±ì„ ë§Œì¡±í•˜ëŠ”ì§€ íŒë‹¨ ê°€ëŠ¥
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from statsmodels.stats.outliers_influence import variance_inflation_factor

from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score, accuracy_score, recall_score, precision_score, f1_score, r2_score, mean_absolute_error, mean_squared_error
from sklearn.model_selection import train_test_split    #train/test ë°ì´í„° ë¶„ë¦¬
from sklearn.linear_model import LinearRegression   #ì„ í˜•íšŒê·€
from sklearn.model_selection import cross_val_score, cross_validate
from sklearn.model_selection import GridSearchCV
#--------------------------------------------------
# ëª¨ë“ˆ ë¶ˆëŸ¬ì˜¤ê¸°
# import sys
# import os
# sys.path.append(os.path.dirname(os.path.dirname(os.getcwd())))
# from helper import normality_test, equal_variance_test, independence_test, all_test
#--------------------------------------------------


# ì‹œê°í™” í°íŠ¸ - tabulateì˜ ìŠ¤íƒ€ì¼ì„ ì§€ì •í•´ ë³€ê²½í•  ìˆ˜ ìˆë‹¤(tablefmt="psql")
def prettyPrint(df, headers="keys", tablefmt="psql", numalign="right", title="value"):
    # print(tabulate(df, headers=headers, tablefmt=tablefmt, numalign=numalign))
    if isinstance(df, Series):
        df = DataFrame(df, columns=[title])
    print(tabulate(df, headers=headers, tablefmt=tablefmt, numalign=numalign))


# ê²°ì¸¡ì¹˜ ì •ì œ(í‰ê·  ê°’)
def replaceMissingValue(df, strategy='mean'):
    """
    ê²°ì¸¡ì¹˜ ì •ì œ

    Parameters
    -------
    - df: ë°ì´í„° í”„ë ˆì„
    - strategy: ê²°ì¸¡ì¹˜ ëŒ€ì²´ ì „ëµ(mean, median, most_frequent). ê¸°ë³¸ê°’ì€ mean

    Returns
    -------
    - re_df: ì •ì œëœ ë°ì´í„° í”„ë ˆì„
    """
    imr = SimpleImputer(missing_values=np.nan, strategy=strategy)
    df_imr = imr.fit_transform(df.values)
    re_df = DataFrame(df_imr, index=df.index, columns=df.columns)
    return re_df


# ë¶„ì‚°ë¶„ì„ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•œ ì •ê·œì„± ê²€ì •
def normality_test(*any):
    """
    ë¶„ì‚°ë¶„ì„ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•œ ì •ê·œì„±ì„ ê²€ì • í•œë‹¤.
    Parameters
    -------
    - any: í•„ë“œë“¤
    Returns
    -------
    - df: ê²€ì • ê²°ê³¼ ë°ì´í„° í”„ë ˆì„
    """
    names = []

    result = {
        'statistic': [],
        'p-value': [],
        'result': []
    }
    for i in any:
        s, p = shapiro(i)
        result['statistic'].append(s)
        result['p-value'].append(p)
        result['result'].append(p > 0.05)
        names.append(('ì •ê·œì„±', 'shapiro', i.name))

    for i in any:
        s, p = normaltest(i)
        result['statistic'].append(s)
        result['p-value'].append(p)
        result['result'].append(p > 0.05)
        names.append(('ì •ê·œì„±', 'normaltest', i.name))

    n = len(any)

    for i in range(0, n):
        j = i + 1 if i < n - 1 else 0

        s, p = ks_2samp(any[i], any[j])
        result['statistic'].append(s)
        result['p-value'].append(p)
        result['result'].append(p > 0.05)
        names.append(('ì •ê·œì„±', 'ks_2samp', f'{any[i].name} vs {any[j].name}'))

    return DataFrame(result, index=MultiIndex.from_tuples(names, names=['condition', 'test', 'field']))


# ë¶„ì‚°ë¶„ì„ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•œ ë“±ë¶„ì‚°ì„± ê²€ì •
def equal_variance_test(*any):
    """
    ë¶„ì‚°ë¶„ì„ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•œ ë“±ë¶„ì‚°ì„±ì„ ê²€ì • í•œë‹¤.
    Parameters
    -------
    - any: í•„ë“œë“¤
    Returns
    -------
    - df: ê²€ì • ê²°ê³¼ ë°ì´í„° í”„ë ˆì„
    """
    # statistic=1.333315753388535, pvalue=0.2633161881599037
    s1, p1 = bartlett(*any)
    s2, p2 = fligner(*any)
    s3, p3 = levene(*any)
    names = []
    for i in any:
        names.append(i.name)

    fix = " vs "
    name = fix.join(names)
    index = [['ë“±ë¶„ì‚°ì„±', 'Bartlett', name], ['ë“±ë¶„ì‚°ì„±', 'Fligner', name], ['ë“±ë¶„ì‚°ì„±', 'Levene', name]]

    df = DataFrame({
        'statistic': [s1, s2, s3],
        'p-value': [p1, p2, p3],
        'result': [p1 > 0.05, p2 > 0.05, p3 > 0.05]
    }, index=MultiIndex.from_tuples(index, names=['condition', 'test', 'field']))

    return df


# ë¶„ì‚°ë¶„ì„ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•œ ë…ë¦½ì„± ê²€ì •
def independence_test(*any):
    """
    ë¶„ì‚°ë¶„ì„ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•œ ë…ë¦½ì„±ì„ ê²€ì •í•œë‹¤.
    Parameters
    -------
    - any: í•„ë“œë“¤
    Returns
    -------
    - df: ê²€ì • ê²°ê³¼ ë°ì´í„° í”„ë ˆì„
    """
    df = DataFrame(any).T
    result = chi2_contingency(df)
    names = []
    for i in any:
        names.append(i.name)
    fix = " vs "
    name = fix.join(names)

    index = [['ë…ë¦½ì„±', 'Chi2', name]]

    df = DataFrame({
        'statistic': [result.statistic],
        'p-value': [result.pvalue],
        'result': [result.pvalue > 0.05]
    }, index=MultiIndex.from_tuples(index, names=['condition', 'test', 'field']))

    return df


# ì •ê·œì„±, ë“±ë¶„ì‚°ì„±, ë…ë¦½ì„±ì„ ëª¨ë‘ ê²€ì •
def all_test(*any):
    """
    ì •ê·œì„±, ë“±ë¶„ì‚°ì„±, ë…ë¦½ì„±ì„ ëª¨ë‘ ê²€ì •í•œë‹¤.
    Parameters
    -------
    - any: í•„ë“œë“¤
    Returns
    -------
    - df: ê²€ì • ê²°ê³¼ ë°ì´í„° í”„ë ˆì„
    """
    return concat([normality_test(*any), equal_variance_test(*any), independence_test(*any)])


# IQR(Interquartile Range)ë¥¼ ì´ìš©í•œ ì´ìƒì¹˜ ê²½ê³„ê°’ ê³„ì‚°
def getIq(field, isPrint=True):
    """
    IQR(Interquartile Range)ë¥¼ ì´ìš©í•œ ì´ìƒì¹˜ ê²½ê³„ê°’ ê³„ì‚°

    Parameters
    ------- 
    - field: ë°ì´í„° í”„ë ˆì„ì˜ í•„ë“œ

    Returns
    -------
    - ê²°ì¸¡ì¹˜ê²½ê³„: ì´ìƒì¹˜ ê²½ê³„ê°’ ë¦¬ìŠ¤íŠ¸
    """
    q1 = field.quantile(q=0.25)
    q3 = field.quantile(q=0.75)
    iqr = q3 - q1
    í•˜í•œ = q1 - 1.5 * iqr
    ìƒí•œ = q3 + 1.5 * iqr
    ê·¹ë‹¨ì¹˜ê²½ê³„ = [í•˜í•œ, ìƒí•œ]   # ì‹œê³„ì—´ì„ ìœ„í•´ ì¶”ê°€

    
    df = DataFrame({
        "ê·¹ë‹¨ì¹˜ ê²½ê³„": [í•˜í•œ, ìƒí•œ]
    }, index=['í•˜í•œ', 'ìƒí•œ'])

    if isPrint:
        prettyPrint(df)
    else:
        return ê·¹ë‹¨ì¹˜ê²½ê³„   # ì‹œê³„ì—´ì„ ìœ„í•´ ì¶”ê°€ ì—¬ê¸°ê¹Œì§€


# ì´ìƒì¹˜ë¥¼ íŒë³„í•˜ì—¬ ê²°ì¸¡ì¹˜ë¡œ ì¹˜í™˜
def replaceOutlier(df, fieldName):
    """
    ì´ìƒì¹˜ë¥¼ íŒë³„í•˜ì—¬ ê²°ì¸¡ì¹˜ë¡œ ì¹˜í™˜

    Parameters
    -------
    - df: ë°ì´í„° í”„ë ˆì„
    - fieldName: ì´ìƒì¹˜ë¥¼ íŒë³„í•  í•„ë“œëª…

    Returns
    -------
    - cdf : ê²°ì¸¡ì¹˜ë¥¼ ì´ìƒì¹˜ë¡œ ì¹˜í™˜í•œ ë°ì´í„° í”„ë ˆì„
    """
    cdf = df.copy()

    # fieldNameì´ Listê°€ ì•„ë‹ˆë©´ Listë¡œ ë³€í™˜
    if not isinstance(fieldName, list):
        fieldName = [fieldName]

    for f in fieldName:
        ê²°ì¸¡ì¹˜ê²½ê³„ = getIq(cdf[f])
        cdf.loc[cdf[f] < ê²°ì¸¡ì¹˜ê²½ê³„[0], f] = np.nan
        cdf.loc[cdf[f] > ê²°ì¸¡ì¹˜ê²½ê³„[1], f] = np.nan

    return cdf


# ë°ì´í„° í”„ë ˆì„ì—ì„œ ì§€ì •ëœ í•„ë“œë¥¼ ë²”ì£¼í˜•ìœ¼ë¡œ ë³€ê²½
def setCategory(df, fields=[], labelling=True):
    """
    ë°ì´í„° í”„ë ˆì„ì—ì„œ ì§€ì •ëœ í•„ë“œë¥¼ ë²”ì£¼í˜•ìœ¼ë¡œ ë³€ê²½í•œë‹¤.

    Parameters
    -------
    - df: ë°ì´í„° í”„ë ˆì„
    - fields: ë²”ì£¼í˜•ìœ¼ë¡œ ë³€ê²½í•  í•„ë“œëª… ë¦¬ìŠ¤íŠ¸. ê¸°ë³¸ê°’ì€ ë¹ˆ ë¦¬ìŠ¤íŠ¸(ì „ì²´ í•„ë“œ ëŒ€ìƒ)

    Returns
    -------
    - cdf: ë²”ì£¼í˜•ìœ¼ë¡œ ë³€ê²½ëœ ë°ì´í„° í”„ë ˆì„
    """
    cdf = df.copy()
    # ë°ì´í„° í”„ë ˆì„ì˜ ë³€ìˆ˜ëª…ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    ilist = list(cdf.dtypes.index)
    # ë°ì´í„° í”„ë ˆì„ì˜ ë³€ìˆ˜í˜•ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    vlist = list(cdf.dtypes.values)

    # ë³€ìˆ˜í˜•ì— ëŒ€í•œ ë°˜ë³µ ì²˜ë¦¬
    for i, v in enumerate(vlist):
        # ë³€ìˆ˜í˜•ì´ objectì´ë©´?
        if v == 'object':
            # ë³€ìˆ˜ëª…ì„ ê°€ì ¸ì˜¨ë‹¤.
            field_name = ilist[i]

            # ëŒ€ìƒ í•„ë“œ ëª©ë¡ì´ ì„¤ì •ë˜ì§€ ì•Šê±°ë‚˜(ì „ì²´í•„ë“œ ëŒ€ìƒ), í˜„ì¬ í•„ë“œê°€ ëŒ€ìƒ í•„ë“œëª©ë¡ì— í¬í•¨ë˜ì–´ ìˆì§€ ì•Šë‹¤ë©´?
            if not fields or field_name not in fields:
                continue

            # ê°€ì ¸ì˜¨ ë³€ìˆ˜ëª…ì— ëŒ€í•´ ê°’ì˜ ì¢…ë¥˜ë³„ë¡œ ë¹ˆë„ë¥¼ ì¹´ìš´íŠ¸ í•œ í›„ ì¸ë±ìŠ¤ ì´ë¦„ìˆœìœ¼ë¡œ ì •ë ¬
            # vc = cdf[field_name].value_counts().sort_index()
            # print(vc)

            # ì¸ë±ìŠ¤ ì´ë¦„ìˆœìœ¼ë¡œ ì •ë ¬ëœ ê°’ì˜ ì¢…ë¥˜ë³„ë¡œ ë°˜ë³µ ì²˜ë¦¬
            # for ii, vv in enumerate(list(vc.index)):
            #     # ì¼ë ¨ë²ˆí˜¸ê°’ìœ¼ë¡œ ì¹˜í™˜
            #     cdf.loc[cdf[field_name] == vv, field_name] = ii

            # í•´ë‹¹ ë³€ìˆ˜ì˜ ë°ì´í„° íƒ€ì…ì„ ë²”ì£¼í˜•ìœ¼ë¡œ ë³€í™˜
            cdf[field_name] = cdf[field_name].astype('category')

            if labelling:
                mydict = {}

                for i, v in enumerate(cdf[field_name].dtypes.categories):
                    mydict[v] = i
                
                cdf[field_name] = cdf[field_name].map(mydict).astype(int)

    return cdf


# ë¶ˆìš©ì–´ë¥¼ ì œê±°
def clearStopwords(nouns, stopwords_file_path="wordcloud/stopwords-ko.txt"):
    """
    ë¶ˆìš©ì–´ë¥¼ ì œê±°í•œë‹¤.

    Parameters
    -------
    - nouns: ëª…ì‚¬ ë¦¬ìŠ¤íŠ¸
    - stopwords_file_path: ë¶ˆìš©ì–´ íŒŒì¼ ê²½ë¡œ. ê¸°ë³¸ê°’ì€ wordcloud/stopwords-ko.txt

    Returns
    -------
    - data_set: ë¶ˆìš©ì–´ê°€ ì œê±°ëœ ëª…ì‚¬ ë¦¬ìŠ¤íŠ¸
    """
    with open(stopwords_file_path, 'r', encoding='utf-8') as f:
        stopwords = f.readlines()

        for i, v in enumerate(stopwords):
            stopwords[i] = v.strip()

    data_set = []

    for v in nouns:
        if v not in stopwords:
            data_set.append(v)

    return data_set


# ì‹ ë¢°êµ¬ê°„ ìƒì„±(ì‹œê³„ì—´ì„ ìœ„í•´ ë³€ê²½)
def getConfidenceInterval(data, clevel=0.95, isPrint=True):
    """
    ì‹ ë¢°êµ¬ê°„ ê³„ì‚°

    Parameters
    -------
    - data: ë°ì´í„°
    - clevel: ì‹ ë¢°ìˆ˜ì¤€. ê¸°ë³¸ê°’ì€ 0.95

    Returns
    -------
    - cmin: ì‹ ë¢°êµ¬ê°„ í•˜í•œ
    - cmax: ì‹ ë¢°êµ¬ê°„ ìƒí•œ
    """
    n = len(data)                           # ìƒ˜í”Œ ì‚¬ì´ì¦ˆ
    dof = n - 1                             # ììœ ë„
    sample_mean = data.mean()               # í‘œë³¸ í‰ê· 
    sample_std = data.std(ddof=1)           # í‘œë³¸ í‘œì¤€ í¸ì°¨
    sample_std_error = sample_std / sqrt(n)  # í‘œë³¸ í‘œì¤€ì˜¤ì°¨

    # ì‹ ë¢°êµ¬ê°„
    cmin, cmax = t.interval(
        clevel, dof, loc=sample_mean, scale=sample_std_error)

    if isPrint:
        df = DataFrame({
            "ì‹ ë¢°êµ¬ê°„": [cmin, cmax]
        }, index=['í•˜í•œ', 'ìƒí•œ'])

        prettyPrint(df)
    else:
        return (cmin, cmax)


# ë¶„ì‚°ë¶„ì„ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•œ ì •ê·œì„±ì„ ê²€ì •
def normalityTest(*any, isPrint=True):
    """
    ë¶„ì‚°ë¶„ì„ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•œ ì •ê·œì„±ì„ ê²€ì • í•œë‹¤.

    Parameters
    -------
    - any: í•„ë“œë“¤

    Returns
    -------
    - df: ê²€ì • ê²°ê³¼ ë°ì´í„° í”„ë ˆì„
    """
    names = []

    result = {
        'field': [],
        'test': [],
        'statistic': [],
        'p-value': [],
        'result': []
    }
    for i in any:
        s, p = shapiro(i)
        result['field'].append(i.name)
        result['test'].append('shapiro')
        result['statistic'].append(s)
        result['p-value'].append(p)
        result['result'].append(p > 0.05)
        names.append('ì •ê·œì„±')

    for i in any:
        s, p = normaltest(i)
        result['field'].append(i.name)
        result['test'].append('shapiro')
        result['statistic'].append(s)
        result['p-value'].append(p)
        result['result'].append(p > 0.05)
        names.append('ì •ê·œì„±')

    n = len(any)

    for i in range(0, n):
        j = i + 1 if i < n - 1 else 0

        s, p = ks_2samp(any[i], any[j])
        result['field'].append(f'{any[i].name} vs {any[j].name}')
        result['test'].append('ks_2samp')
        result['statistic'].append(s)
        result['p-value'].append(p)
        result['result'].append(p > 0.05)
        names.append('ì •ê·œì„±')

    rdf = DataFrame(result, index=names)

    if isPrint:
        prettyPrint(rdf)
    else:
        return rdf


# ë¶„ì‚°ë¶„ì„ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•œ ë“±ë¶„ì‚°ì„±ì„ ê²€
def equalVarianceTest(*any, isPrint=True):
    """
    ë¶„ì‚°ë¶„ì„ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•œ ë“±ë¶„ì‚°ì„±ì„ ê²€ì • í•œë‹¤.

    Parameters
    -------
    - any: í•„ë“œë“¤

    Returns
    -------
    - df: ê²€ì • ê²°ê³¼ ë°ì´í„° í”„ë ˆì„
    """
    s1, p1 = bartlett(*any)
    s2, p2 = fligner(*any)
    s3, p3 = levene(*any)

    names = []

    for i in any:
        names.append(i.name)

    fix = " vs "
    name = fix.join(names)
    index = ['ë“±ë¶„ì‚°ì„±', 'ë“±ë¶„ì‚°ì„±', 'ë“±ë¶„ì‚°ì„±']

    df = DataFrame({
        'field': [name, name, name],
        'test': ['Bartlett', 'Fligner', 'Levene'],
        'statistic': [s1, s2, s3],
        'p-value': [p1, p2, p3],
        'result': [p1 > 0.05, p2 > 0.05, p3 > 0.05]
    }, index=index)

    if isPrint:
        prettyPrint(df)
    else:
        return df


# ë¶„ì‚°ë¶„ì„ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•œ ë…ë¦½ì„±ì„ ê²€ì •
def independenceTest(*any, isPrint=True):
    """
    ë¶„ì‚°ë¶„ì„ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•œ ë…ë¦½ì„±ì„ ê²€ì •í•œë‹¤.

    Parameters
    -------
    - any: í•„ë“œë“¤

    Returns
    -------
    - df: ê²€ì • ê²°ê³¼ ë°ì´í„° í”„ë ˆì„
    """
    df = DataFrame(any).T
    result = chi2_contingency(df)

    names = []

    for i in any:
        names.append(i.name)

    fix = " vs "
    name = fix.join(names)

    index = ['ë…ë¦½ì„±']

    df = DataFrame({
        'field': [name],
        'test': ['Chi2'],
        'statistic': [result.statistic],
        'p-value': [result.pvalue],
        'result': [result.pvalue > 0.05]
    }, index=index)

    if isPrint:
        prettyPrint(df)
    else:
        return df


# ì •ê·œì„±, ë“±ë¶„ì‚°ì„±, ë…ë¦½ì„±ì„ ëª¨ë‘ ê²€ì •
def allTest(*any, isPrint=True):
    """
    ì •ê·œì„±, ë“±ë¶„ì‚°ì„±, ë…ë¦½ì„±ì„ ëª¨ë‘ ê²€ì •í•œë‹¤.

    Parameters
    -------
    - any: í•„ë“œë“¤

    Returns
    -------
    - df: ê²€ì • ê²°ê³¼ ë°ì´í„° í”„ë ˆì„
    """
    cc = concat([normalityTest(*any, isPrint=False), equalVarianceTest(*any, isPrint=False), independenceTest(*any, isPrint=False)])

    if isPrint:
        prettyPrint(cc)
    else:
        return cc


#------------------------------
# í”¼ì–´ìŠ¨ ìƒê´€ë¶„ì„
#------------------------------
# í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒê´€ë¶„ì„ì„ ìˆ˜í–‰
def pearson_r(df, isPrint=True):
    """
    í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒê´€ë¶„ì„ì„ ìˆ˜í–‰í•œë‹¤.

    Parameters
    -------
    - df: ë°ì´í„° í”„ë ˆì„

    Returns
    -------
    - rdf: ìƒê´€ë¶„ì„ ê²°ê³¼ ë°ì´í„° í”„ë ˆì„
    """
    names = df.columns
    n = len(names)
    pv = 0.05

    data = []

    for i in range(0, n):
        # ê¸°ë³¸ì ìœ¼ë¡œ i ë‹¤ìŒ ìœ„ì¹˜ë¥¼ ì˜ë¯¸í•˜ì§€ë§Œ iê°€ ë§ˆì§€ë§‰ ì¸ë±ìŠ¤ì¼ ê²½ìš° 0ìœ¼ë¡œ ì„¤ì •
        j = i + 1 if i < n - 1 else 0

        fields = names[i] + ' vs ' + names[j]
        s, p = pearsonr(df[names[i]], df[names[j]])
        result = p < pv

        data.append({'fields': fields, 'statistic': s,
                    'pvalue': p, 'result': result})

    rdf = DataFrame(data)
    rdf.set_index('fields', inplace=True)

    if isPrint:
        prettyPrint(rdf)
    else:
        return rdf
#------------------------------
# ìŠ¤í”¼ì–´ë§Œ ìƒê´€ë¶„ì„
#------------------------------
# ìŠ¤í”¼ì–´ë§Œ ìƒê´€ê³„ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒê´€ë¶„ì„ì„ ìˆ˜í–‰
def spearman_r(df, isPrint=True):
    """
    ìŠ¤í”¼ì–´ë§Œ ìƒê´€ê³„ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒê´€ë¶„ì„ì„ ìˆ˜í–‰í•œë‹¤.

    Parameters
    -------
    - df: ë°ì´í„° í”„ë ˆì„

    Returns
    -------
    - rdf: ìƒê´€ë¶„ì„ ê²°ê³¼ ë°ì´í„° í”„ë ˆì„
    """
    names = df.columns
    n = len(names)
    pv = 0.05

    data = []

    for i in range(0, n):
        # ê¸°ë³¸ì ìœ¼ë¡œ i ë‹¤ìŒ ìœ„ì¹˜ë¥¼ ì˜ë¯¸í•˜ì§€ë§Œ iê°€ ë§ˆì§€ë§‰ ì¸ë±ìŠ¤ì¼ ê²½ìš° 0ìœ¼ë¡œ ì„¤ì •
        j = i + 1 if i < n - 1 else 0

        fields = names[i] + ' vs ' + names[j]
        s, p = spearmanr(df[names[i]], df[names[j]])
        result = p < pv

        data.append({'fields': fields, 'statistic': s,
                    'pvalue': p, 'result': result})

    rdf = DataFrame(data)
    rdf.set_index('fields', inplace=True)

    if isPrint:
        prettyPrint(rdf)
    else:
        return rdf


'''
# ëª¨ë“ˆ ì§€ì •
ì„¤ëª…ë ¥
í‰ê· ì ˆëŒ€ì˜¤ì°¨
í‰ê· ì œê³±ì˜¤ì°¨
í‰ê· ì˜¤ì°¨
í‰ê·  ì ˆëŒ€ ë°±ë¶„ ì˜¤ì°¨ ë¹„ìœ¨
í‰ê·  ë¹„ìœ¨ ì˜¤ì°¨
'''
class RegMetric:
    def __init__(self, y, y_pred):
        # ì„¤ëª…ë ¥
        self._r2 = r2_score(y, y_pred)
        # í‰ê· ì ˆëŒ€ì˜¤ì°¨
        self._mae = mean_absolute_error(y, y_pred)
        # í‰ê·  ì œê³± ì˜¤ì°¨
        self._mse = mean_squared_error(y, y_pred)
        # í‰ê·  ì˜¤ì°¨
        self._rmse = np.sqrt(self._mse)

        # í‰ê·  ì ˆëŒ€ ë°±ë¶„ì˜¤ì°¨ ë¹„ìœ¨
        if type(y) == Series:
            self._mape = np.mean(np.abs((y.values - y_pred) / y.values) * 100)
        else:
            self._mape = np.mean(np.abs((y - y_pred) / y) * 100)

        # í‰ê·  ë¹„ìœ¨ ì˜¤ì°¨
        if type(y) == Series:   
            self._mpe = np.mean((y.values - y_pred) / y.values * 100)
        else:
            self._mpe = np.mean((y - y_pred) / y * 100)

    @property
    def r2(self):
        return self._r2

    @r2.setter
    def r2(self, value):
        self._r2 = value

    @property
    def mae(self):
        return self._mae

    @mae.setter
    def mae(self, value):
        self._mae = value

    @property
    def mse(self):
        return self._mse

    @mse.setter
    def mse(self, value):
        self._mse = value

    @property
    def rmse(self):
        return self._rmse

    @rmse.setter
    def rmse(self, value):
        self._rmse = value

    @property
    def mape(self):
        return self._mape

    @mape.setter
    def mape(self, value):
        self._mape = value

    @property
    def mpe(self):
        return self._mpe

    @mpe.setter
    def mpe(self, value):
        self._mpe = value     
        

# íšŒê·€ë¶„ì„ ê²°ê³¼ë¥¼ ìœ„í•œ class
class OlsResult:
    def __init__(self):
        self._x_train = None    #ë¨¸ì‹ ëŸ¬ë‹ íšŒê·€ ê°±ì‹ 
        self._y_train = None
        self._train_pred = None
        self._x_test = None
        self._y_test = None
        self._test_pred = None  #ë¨¸ì‹ ëŸ¬ë‹ íšŒê·€ ê°±ì‹ 

        self._model = None
        self._fit = None
        self._summary = None
        self._table = None
        self._result = None
        self._goodness = None
        self._varstr = None
        self._coef = None   #ê¸°ìš¸ê¸°
        self._intercept = None  #ì ˆí¸
        self._trainRegMetric = None #í•™ìŠµ
        self._testRegMetric = None  #í…ŒìŠ¤íŠ¸

    #ë¨¸ì‹ ëŸ¬ë‹ íšŒê·€ ê°±ì‹ 
    @property
    def x_train(self):
        return self._x_train

    @x_train.setter
    def x_train(self, value):
        self._x_train = value

    @property
    def y_train(self):
        return self._y_train

    @y_train.setter
    def y_train(self, value):
        self._y_train = value

    @property
    def train_pred(self):
        return self._train_pred

    @train_pred.setter
    def train_pred(self, value):
        self._train_pred = value

    @property
    def x_test(self):
        return self._x_test

    @x_test.setter
    def x_test(self, value):
        self._x_test = value

    @property
    def y_test(self):
        return self._y_test

    @y_test.setter
    def y_test(self, value):
        self._y_test = value

    @property
    def test_pred(self):
        return self._test_pred

    @test_pred.setter
    def test_pred(self, value):
        self._test_pred = value
    #ë¨¸ì‹ ëŸ¬ë‹ íšŒê·€ ê°±ì‹ 

    @property
    def model(self):
        """
        ë¶„ì„ëª¨ë¸
        """
        return self._model

    @model.setter
    def model(self, value):
        self._model = value

    @property
    def fit(self):
        """
        ë¶„ì„ê²°ê³¼ ê°ì²´
        """
        return self._fit

    @fit.setter
    def fit(self, value):
        self._fit = value

    @property
    def summary(self):
        """
        ë¶„ì„ê²°ê³¼ ìš”ì•½ ë³´ê³ 
        """
        return self._summary

    @summary.setter
    def summary(self, value):
        self._summary = value

    @property
    def table(self):
        """
        ê²°ê³¼í‘œ
        """
        return self._table

    @table.setter
    def table(self, value):
        self._table = value

    @property
    def result(self):
        """
        ê²°ê³¼í‘œ ë¶€ê°€ ì„¤ëª…
        """
        return self._result

    @result.setter
    def result(self, value):
        self._result = value

    @property
    def goodness(self):
        """
        ëª¨í˜• ì í•©ë„ ë³´ê³ 
        """
        return self._goodness

    @goodness.setter
    def goodness(self, value):
        self._goodness = value

    @property
    def varstr(self):
        """
        ë…ë¦½ë³€ìˆ˜ ë³´ê³ 
        """
        return self._varstr

    @varstr.setter
    def varstr(self, value):
        self._varstr = value

    @property
    def coef(self):   #ê¸°ìš¸ê¸°
        return self._coef

    @coef.setter
    def coef(self, value):
        self._coef = value

    @property
    def intercept(self):    #ì ˆí¸
        return self._intercept

    @intercept.setter
    def intercept(self, value):
        self._intercept = value

    @property
    def trainRegMetric(self):   #í•™ìŠµ
        return self._trainRegMetric

    @trainRegMetric.setter
    def trainRegMetric(self, value):
        self._trainRegMetric = value

    @property
    def testRegMetric(self):    #í…ŒìŠ¤íŠ¸
        return self._testRegMetric

    @testRegMetric.setter
    def testRegMetric(self, value):
        self._testRegMetric = value

    def setRegMetric(self, y_train, y_train_pred, y_test=None, y_test_pred=None):
        self.trainRegMetric = RegMetric(y_train, y_train_pred)
        
        if y_test is not None and y_test_pred is not None:
            self.testRegMetric = RegMetric(y_test, y_test_pred)


# íšŒê·€ë¶„ì„ì„ ìˆ˜í–‰
def myOls(data, y=None, x=None, expr=None):
    """
    íšŒê·€ë¶„ì„ì„ ìˆ˜í–‰í•œë‹¤.

    Parameters
    -------
    - data : ë°ì´í„° í”„ë ˆì„
    - y: ì¢…ì†ë³€ìˆ˜ ì´ë¦„
    - x: ë…ë¦½ë³€ìˆ˜ì˜ ì´ë¦„ë“¤(ë¦¬ìŠ¤íŠ¸)
    """

    # DF ë³µì‚¬
    df = data.copy()

    # ì¢…ì†ë³€ìˆ˜~ë…ë¦½ë³€ìˆ˜1+ë…ë¦½ë³€ìˆ˜2+ë…ë¦½ë³€ìˆ˜3+... í˜•íƒœì˜ ì‹ì„ ìƒì„±
    if not expr:
        # ë…ë¦½ë³€ìˆ˜ì˜ ì´ë¦„ì´ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹ˆë¼ë©´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        if type(x) != list:
            x = [x]
        expr = "%s~%s" % (y, "+".join(x))
    else:
        x = []
        p = expr.find('~')
        y = expr[:p].strip()
        x_tmp = expr[p+1:]
        x_list = x_tmp.split('+')

        for i in x_list:
            k = i.strip()

            if k:
                x.append(k)


    # íšŒê·€ëª¨ë¸ ìƒì„±
    model = ols(expr, data=data)
    # ë¶„ì„ ìˆ˜í–‰
    fit = model.fit()

    # íŒŒì´ì¬ ë¶„ì„ê²°ê³¼ë¥¼ ë³€ìˆ˜ì— ì €ì¥í•œë‹¤.
    summary = fit.summary()

    # ì²« ë²ˆì§¸, ì„¸ ë²ˆì§¸ í‘œì˜ ë‚´ìš©ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë¶„í•´
    my = {}

    for k in range(0, 3, 2):
        items = summary.tables[k].data
        # print(items)

        for item in items:
            # print(item)
            n = len(item)

            for i in range(0, n, 2):
                key = item[i].strip()[:-1]
                value = item[i+1].strip()

                if key and value:
                    my[key] = value

    # ë‘ ë²ˆì§¸ í‘œì˜ ë‚´ìš©ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë¶„í•´í•˜ì—¬ myì— ì¶”ê°€
    my['variables'] = []
    name_list = list(data.columns)
    #print(name_list)

    for i, v in enumerate(summary.tables[1].data):
        if i == 0:
            continue

        # ë³€ìˆ˜ì˜ ì´ë¦„
        name = v[0].strip()

        vif = 0

        # InterceptëŠ” ì œì™¸
        if name in name_list:
            # ë³€ìˆ˜ì˜ ì´ë¦„ ëª©ë¡ì—ì„œ í˜„ì¬ ë³€ìˆ˜ê°€ ëª‡ ë²ˆì§¸ í•­ëª©ì¸ì§€ ì°¾ê¸° 
            j = name_list.index(name)
            vif = variance_inflation_factor(data, j)

        my['variables'].append({
            "name": name,
            "coef": v[1].strip(),
            "std err": v[2].strip(),
            "t": v[3].strip(),
            "P-value": v[4].strip(),
            "Beta": 0,
            "VIF": vif,
        })

    # ê²°ê³¼í‘œë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ êµ¬ì„±
    mylist = []
    yname_list = []
    xname_list = []

    for i in my['variables']:
        if i['name'] == 'Intercept':
            continue

        yname_list.append(y)
        xname_list.append(i['name'])

        item = {
            "B": i['coef'],
            "í‘œì¤€ì˜¤ì°¨": i['std err'],
            "Î²": i['Beta'],
            "t": "%s*" % i['t'],
            "ìœ ì˜í™•ë¥ ": i['P-value'],
            "VIF": i["VIF"]
        }

        mylist.append(item)

    table = DataFrame(mylist,
                   index=MultiIndex.from_arrays([yname_list, xname_list], names=['ì¢…ì†ë³€ìˆ˜', 'ë…ë¦½ë³€ìˆ˜']))
    
    # ë¶„ì„ê²°ê³¼
    result = "ğ‘…(%s), ğ‘…^2(%s), ğ¹(%s), ìœ ì˜í™•ë¥ (%s), Durbin-Watson(%s)" % (my['R-squared'], my['Adj. R-squared'], my['F-statistic'], my['Prob (F-statistic)'], my['Durbin-Watson'])

    # ëª¨í˜• ì í•©ë„ ë³´ê³ 
    goodness = "%sì— ëŒ€í•˜ì—¬ %së¡œ ì˜ˆì¸¡í•˜ëŠ” íšŒê·€ë¶„ì„ì„ ì‹¤ì‹œí•œ ê²°ê³¼, ì´ íšŒê·€ëª¨í˜•ì€ í†µê³„ì ìœ¼ë¡œ %s(F(%s,%s) = %s, p < 0.05)." % (y, ",".join(x), "ìœ ì˜í•˜ë‹¤" if float(my['Prob (F-statistic)']) < 0.05 else "ìœ ì˜í•˜ì§€ ì•Šë‹¤", my['Df Model'], my['Df Residuals'], my['F-statistic'])

    # ë…ë¦½ë³€ìˆ˜ ë³´ê³ 
    varstr = []

    for i, v in enumerate(my['variables']):
        if i == 0:
            continue
        
        s = "%sì˜ íšŒê·€ê³„ìˆ˜ëŠ” %s(p%s0.05)ë¡œ, %sì— ëŒ€í•˜ì—¬ %s."
        k = s % (v['name'], v['coef'], "<" if float(v['P-value']) < 0.05 else '>', y, 'ìœ ì˜ë¯¸í•œ ì˜ˆì¸¡ë³€ì¸ì¸ ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ë‹¤' if float(v['P-value']) < 0.05 else 'ìœ ì˜í•˜ì§€ ì•Šì€ ì˜ˆì¸¡ë³€ì¸ì¸ ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ë‹¤')

        varstr.append(k)

    ols_result = OlsResult()
    ols_result.model = model
    ols_result.fit = fit
    ols_result.summary = summary
    ols_result.table = table
    ols_result.result = result
    ols_result.goodness = goodness
    ols_result.varstr = varstr

    return ols_result


# ë°ì´í„° í”„ë ˆì„ì„ í‘œì¤€í™”-ì •ê·œí™”(scaling)
def scalling(df, yname=None):
    """
    ë°ì´í„° í”„ë ˆì„ì„ í‘œì¤€í™” í•œë‹¤.

    Parameters
    -------
    - df: ë°ì´í„° í”„ë ˆì„
    - yname: ì¢…ì†ë³€ìˆ˜ ì´ë¦„

    Returns
    -------
    - x_train_std_df: í‘œì¤€í™”ëœ ë…ë¦½ë³€ìˆ˜ ë°ì´í„° í”„ë ˆì„
    - y_train_std_df: í‘œì¤€í™”ëœ ì¢…ì†ë³€ìˆ˜ ë°ì´í„° í”„ë ˆì„
    """
    # í‰ì†Œì—ëŠ” ynameì„ ì œê±°í•œ í•­ëª©ì„ ì‚¬ìš©
    # ynameì´ ìˆì§€ ì•Šë‹¤ë©´ dfë¥¼ ë³µì‚¬
    x_train = df.drop([yname], axis=1) if yname else df.copy()
    x_train_std = StandardScaler().fit_transform(x_train)
    x_train_std_df = DataFrame(x_train_std, columns=x_train.columns)
    
    if yname:
        y_train = df.filter([yname])
        y_train_std = StandardScaler().fit_transform(y_train)
        y_train_std_df = DataFrame(y_train_std, columns=y_train.columns)

    if yname:
        result = (x_train_std_df, y_train_std_df)
    else:
        result = x_train_std_df

    return result


#------------------------------
# ì‹œê³„ì—´ë°ì´í„°ë¶„ì„
# íšŒê·€ë¶„ì„ì— í•„ìš”í•œ ìš”ì¸ ì„ ì •ì„ ìœ„í•´
# ì£¼ì„±ë¶„ ë¶„ì„ì„ ìˆ˜í–‰
#------------------------------
# ì£¼ì„±ë¶„ ë¶„ì„-PCA ë¶„ì„
def getBestFeatures(x_train_std_df):
    pca_model = pca()
    fit = pca_model.fit_transform(x_train_std_df)
    topfeat_df = fit['topfeat']
    
    best = topfeat_df.query("type=='best'")
    feature = list(set(list(best['feature'])))
    
    return (feature, topfeat_df)


# ë¡œì§€ìŠ¤í‹± íšŒê·€ë¶„ì„ ê²°ê³¼ë¥¼ ìœ„í•œ class
class LogitResult:
    def __init__(self):
        self._model = None    
        self._fit = None
        self._summary = None
        self._prs = None
        self._cmdf = None
        self._result_df = None
        self._odds_rate_df = None

    @property
    def model(self):
        return self._model

    @model.setter
    def model(self, value):
        self._model = value

    @property
    def fit(self):
        return self._fit

    @fit.setter
    def fit(self, value):
        self._fit = value

    @property
    def summary(self):
        return self._summary

    @summary.setter
    def summary(self, value):
        self._summary = value

    @property
    def prs(self):
        return self._prs

    @prs.setter
    def prs(self, value):
        self._prs = value

    @property
    def cmdf(self):
        return self._cmdf

    @cmdf.setter
    def cmdf(self, value):
        self._cmdf = value

    @property
    def result_df(self):
        return self._result_df

    @result_df.setter
    def result_df(self, value):
        self._result_df = value

    @property
    def odds_rate_df(self):
        return self._odds_rate_df

    @odds_rate_df.setter
    def odds_rate_df(self, value):
        self._odds_rate_df = value

# ë¡œì§€ìŠ¤í‹± íšŒê·€ë¶„ì„ì„ ìˆ˜í–‰
def myLogit(data, y, x, subset=None):
    """
    ë¡œì§€ìŠ¤í‹± íšŒê·€ë¶„ì„ì„ ìˆ˜í–‰í•œë‹¤.

    Parameters
    -------
    - data : ë°ì´í„° í”„ë ˆì„
    - y: ì¢…ì†ë³€ìˆ˜ ì´ë¦„
    - x: ë…ë¦½ë³€ìˆ˜ì˜ ì´ë¦„ë“¤(ë¦¬ìŠ¤íŠ¸)
    """

    # ë°ì´í„°í”„ë ˆì„ ë³µì‚¬
    df = data.copy()

    # ë…ë¦½ë³€ìˆ˜ì˜ ì´ë¦„ì´ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹ˆë¼ë©´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    if type(x) != list:
        x = [x]

    # ì¢…ì†ë³€ìˆ˜~ë…ë¦½ë³€ìˆ˜1+ë…ë¦½ë³€ìˆ˜2+ë…ë¦½ë³€ìˆ˜3+... í˜•íƒœì˜ ì‹ì„ ìƒì„±
    expr = "%s~%s" % (y, "+".join(x))

    # íšŒê·€ëª¨ë¸ ìƒì„±
    model = logit(expr, data=df)
    # ë¶„ì„ ìˆ˜í–‰
    fit = model.fit()

    # íŒŒì´ì¬ ë¶„ì„ê²°ê³¼ë¥¼ ë³€ìˆ˜ì— ì €ì¥í•œë‹¤.
    summary = fit.summary()

    # ì˜ì‚¬ê²°ì •ê³„ìˆ˜
    prs = fit.prsquared

    # ì˜ˆì¸¡ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„ì— ì¶”ê°€
    df['ì˜ˆì¸¡ê°’'] = fit.predict(df.drop([y], axis=1))
    df['ì˜ˆì¸¡ê²°ê³¼'] = df['ì˜ˆì¸¡ê°’'] > 0.5

    # í˜¼ë™í–‰ë ¬
    cm = confusion_matrix(df[y], df['ì˜ˆì¸¡ê²°ê³¼'])
    tn, fp, fn, tp = cm.ravel()
    cmdf = DataFrame([[tn, fn], [fp, tp]], index=['True', 'False'], columns=['Negative', 'Positive'])

    # RAS
    ras = roc_auc_score(df[y], df['ì˜ˆì¸¡ê²°ê³¼'])

    # ìœ„ì–‘ì„±ìœ¨, ì¬í˜„ìœ¨, ì„ê³„ê°’(ì‚¬ìš©ì•ˆí•¨)
    fpr, tpr, thresholds = roc_curve(df[y], df['ì˜ˆì¸¡ê²°ê³¼'])

    # ì •í™•ë„
    acc = accuracy_score(df[y], df['ì˜ˆì¸¡ê²°ê³¼'])

    # ì •ë°€ë„
    pre = precision_score(df[y], df['ì˜ˆì¸¡ê²°ê³¼'])

    # ì¬í˜„ìœ¨
    recall = recall_score(df[y], df['ì˜ˆì¸¡ê²°ê³¼'])

    # F1 score
    f1 = f1_score(df[y], df['ì˜ˆì¸¡ê²°ê³¼'])

    # ìœ„ì–‘ì„±ìœ¨
    fallout = fp / (fp + tn)

    # íŠ¹ì´ì„±
    spe = 1 - fallout

    result_df = DataFrame({'ì„¤ëª…ë ¥(Pseudo-Rsqe)': [fit.prsquared], 'ì •í™•ë„(Accuracy)':[acc], 'ì •ë°€ë„(Precision)':[pre], 'ì¬í˜„ìœ¨(Recall, TPR)':[recall], 'ìœ„ì–‘ì„±ìœ¨(Fallout, FPR)': [fallout], 'íŠ¹ì´ì„±(Specificity, TNR)':[spe], 'RAS': [ras], 'f1_score':[f1]})

    # ì˜¤ì¦ˆë¹„
    coef = fit.params
    odds_rate = np.exp(coef)
    odds_rate_df = DataFrame(odds_rate, columns=['odds_rate'])
    
    #return (model, fit, summary, prs, cmdf, result_df, odds_rate_df)

    logit_result = LogitResult()
    logit_result.model = model
    logit_result.fit = fit
    logit_result.summary = summary
    logit_result.prs = prs
    logit_result.cmdf = cmdf
    logit_result.result_df = result_df
    logit_result.odds_rate_df = odds_rate_df

    return logit_result


#------------------------------
# ì‹œê³„ì—´ë°ì´í„°ë¶„ì„
#------------------------------
# ì‹œê³„ì—´ ë°ì´í„° ë¶„ì„(ì°¨ë¶„ì„ ìˆ˜í–‰í•´ ìµœì ì˜ ê²°ê³¼ë¥¼ ìœ ë„)
def expTimeData(data, yname, sd_model="m", max_diff=1):
    plt.rcParams["font.family"] = 'AppleGothic' if sys.platform == 'darwin' else 'Malgun Gothic'
    plt.rcParams["font.size"] = 12
    plt.rcParams["axes.unicode_minus"] = False

    df = data.copy()

    # ë°ì´í„° ì •ìƒì„± ì—¬ë¶€
    stationarity = False

    # ë°˜ë³µ ìˆ˜í–‰ íšŸìˆ˜
    count = 0

    # ê²°ì¸¡ì¹˜ ì¡´ì¬ ì—¬ë¶€
    na_count = df[yname].isna().sum()
    print("ê²°ì¸¡ì¹˜ ìˆ˜: %d" % na_count)

    plt.figure(figsize=(4, 5))
    sb.boxplot(data=df, y=yname)
    plt.show()
    plt.close()
    
    # ì‹œê³„ì—´ ë¶„í•´
    model_name = 'multiplicative' if sd_model == 'm' else 'additive'
    sd = seasonal_decompose(df[yname], model=model_name)

    figure = sd.plot()
    figure.set_figwidth(15)
    figure.set_figheight(16)
    fig, ax1, ax2, ax3, ax4 = figure.get_children()
    figure.subplots_adjust(hspace=0.4)

    ax1.set_ylabel("Original")
    ax1.grid(True)
    ax1.title.set_text("Original")
    ax2.grid(True)
    ax2.title.set_text("Trend")
    ax3.grid(True)
    ax3.title.set_text("Seasonal")
    ax4.grid(True)
    ax4.title.set_text("Residual")

    plt.show()

    # ACF, PACF ê²€ì •
    fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(15, 12))
    fig.subplots_adjust(hspace=0.4)

    sb.lineplot(data=df, x=df.index, y=yname, ax=ax1)
    ax1.title.set_text("Original")

    plot_acf(df[yname], ax=ax2)
    ax2.title.set_text("ACF Test")
        
    plot_pacf(df[yname], ax=ax3)
    ax3.title.set_text("PACF Test")
        
    plt.show()
    plt.close()

    while not stationarity:
        if count == 0:
            print("=========== ì›ë³¸ ë°ì´í„° ===========")
        else:
            print("=========== %dì°¨ ì°¨ë¶„ ë°ì´í„° ===========" % count)

        # ADF Test
        ar = adfuller(df[yname])

        ardict = {
            'ê²€ì •í†µê³„ëŸ‰(ADF Statistic)': [ar[0]],
            'ìœ ì˜ìˆ˜ì¤€(p-value)': [ar[1]],
            'ìµœì ì°¨ìˆ˜(num of lags)': [ar[2]],
            'ê´€ì¸¡ì¹˜ ê°œìˆ˜(num of observations)': [ar[3]]   
        }

        for key, value in ar[4].items():
            ardict['ê¸°ê°ê°’(Critical Values) %s' % key] = value

        stationarity = ar[1] < 0.05
        ardict['ë°ì´í„° ì •ìƒì„± ì—¬ë¶€(0=False,1=True)'] = stationarity

        ardf = DataFrame(ardict, index=['ADF Test']).T

        print(tabulate(ardf, headers=["ADF Test", ""], tablefmt='psql', numalign="right"))

        # ì°¨ë¶„ ìˆ˜í–‰
        df = df.diff().dropna()

        # ë°˜ë³µì„ ê³„ì†í• ì§€ ì—¬ë¶€ íŒë‹¨
        count += 1
        if count == max_diff:
            break

# ì‹œê³„ì—´ ë°ì´í„° ë¶„ì„(ì°¨ë¶„ì„ ìˆ˜í–‰í•´ ìµœì ì˜ ê²°ê³¼ë¥¼ ìœ ë„)
def exp_time_data(data, yname, sd_model="m", max_diff=1):
    expTimeData(data, yname, sd_model, max_diff)


#------------------------------
# ì‹œê³„ì—´ë°ì´í„°ë¶„ì„
#------------------------------
# ë°ì´í„° í”„ë ˆì„ì˜ ì¸ë±ìŠ¤ë¥¼ datetime í˜•ì‹ìœ¼ë¡œ ë³€í™˜
def set_datetime_index(df, field=None, inplace=False):
    """
        ë°ì´í„° í”„ë ˆì„ì˜ ì¸ë±ìŠ¤ë¥¼ datetime í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        Parameters
        -------
        - df: ë°ì´í„° í”„ë ˆì„
        - inplace: ì›ë³¸ ë°ì´í„° í”„ë ˆì„ì— ì ìš© ì—¬ë¶€
        Returns
        -------
        - ì¸ë±ìŠ¤ê°€ datetime í˜•ì‹ìœ¼ë¡œ ë³€í™˜ëœ ë°ì´í„° í”„ë ˆì„
    """

    if inplace:
        if field is not None:
            df.set_index(field, inplace=True)

        df.index = DatetimeIndex(df.index.values, freq=df.index.inferred_freq)
        df.sort_index(inplace=True)
    else:
        cdf = df.copy()

        if field is not None:
            cdf.set_index(field, inplace=True)

        cdf.index = DatetimeIndex(cdf.index.values, freq=cdf.index.inferred_freq)
        cdf.sort_index(inplace=True)
        return cdf
    


#------------------------------
# ë¨¸ì‹ ëŸ¬ë‹
#------------------------------
# ë‹¤í•­ì‹ ë³€í™˜
def convertPoly(data, degree=2, include_bias=False):
    poly = PolynomialFeatures(degree=degree, include_bias=include_bias)
    fit = poly.fit_transform(data)
    x = DataFrame(fit, columns=poly.get_feature_names_out())
    return x

# ë¨¸ì‹ ëŸ¬ë‹ ì¶”ì„¸ì„  ìœ ë„
def getTrend(x, y, degree=2, value_count=100):
    # degree=2 -> [ a, b, c ] ==> ax^2 + bx + c
    coeff = np.polyfit(x, y, degree)    #xì— ë”°ë¼ yê°’ì´ ë³€í•˜ëŠ” 2ì°¨ ë°©ì •ì‹ ìƒì„±

    if type(x) == 'list':   #xê°€ list í˜•ì‹ì¸ ê²½ìš°
        minx = min(x)
        maxx = max(x)
    else:
        minx = x.min()
        maxx = x.max()

    Vtrend = np.linspace(minx, maxx, value_count)   #í‰ë©´ì¢Œí‘œ ìƒì—ì„œì˜ ê°€ìƒì˜ xê°’

    Ttrend = coeff[-1]  #ìƒì„±ëœ xê°’ì— ë”°ë¥¸ yê°’
    for i in range(0, degree):
        Ttrend += coeff[i] * Vtrend ** (degree - i)

    return (Vtrend, Ttrend)


'''
def regplot ë³€ìˆ˜ì„¤ëª…
x_left : ì™¼ìª½ ê·¸ë˜í”„ì˜ x ì¶• ë°ì´í„°
y_left : ì™¼ìª½ ê·¸ë˜í”„ì˜ y ì¶• ë°ì´í„°
y_left_pred : ì™¼ìª½ ê·¸ë˜í”„ì—ì„œì˜ ì˜ˆì¸¡ëœ y ê°’ ë°ì´í„°
ê°’ì´ ì£¼ì–´ì§€ë©´ ì˜ˆì¸¡ëœ ë°ì´í„°ì— ëŒ€í•œ ì‚°ì ë„ì™€ ì¶”ì„¸ì„ ì´ í•¨ê»˜ ì‘ì„±
left_title : ì™¼ìª½ ê·¸ë˜í”„ì˜ ì œëª©
x_right : ì˜¤ë¥¸ìª½ ê·¸ë˜í”„ì˜ x ì¶• ë°ì´í„°
ê°’ì´ ì£¼ì–´ì§€ë©´ ì˜¤ë¥¸ìª½ ê·¸ë˜í”„ ì‘ì„±
y_right : ì˜¤ë¥¸ìª½ ê·¸ë˜í”„ì˜ y ì¶• ë°ì´í„°
y_right_pred : ì˜¤ë¥¸ìª½ ê·¸ë˜í”„ì—ì„œì˜ ì˜ˆì¸¡ëœ y ê°’ ë°ì´í„°
ê°’ì´ ì£¼ì–´ì§€ë©´ ì˜¤ë¥¸ìª½ ê·¸ë˜í”„ì— ì˜ˆì¸¡ëœ ë°ì´í„°ì— ëŒ€í•œ ì‚°ì ë„ì™€ ì¶”ì„¸ì„  ì‘ì„±
right_title : ì˜¤ë¥¸ìª½ ê·¸ë˜í”„ì˜ ì œëª©
save_path : ê·¸ë˜í”„ë¥¼ ì €ì¥í•  íŒŒì¼ ê²½ë¡œ
ê°’ì´ ì£¼ì–´ì§€ë©´ ê·¸ë˜í”„ë¥¼ í•´ë‹¹ ê²½ë¡œì— ì €ì¥
getTrend() : ì¶”ì„¸ì„ ì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜
x, y ë°ì´í„°ì— ëŒ€í•œ ì¶”ì„¸ì„ ì˜ x, y ê°’ì„ ë°˜í™˜
'''
def regplot(x_left, y_left, y_left_pred=None, left_title=None, x_right=None, y_right=None, y_right_pred=None, right_title=None, figsize=(10, 5), save_path=None):
    # x_left, y_leftëŠ” í•„ìˆ˜ ì…ë ¥ ì‚¬í•­
    subcount = 1 if x_right is None else 2

    fig, ax = plt.subplots(1, subcount, figsize=figsize)

    axmain = ax if subcount == 1 else ax[0]

    # ì™¼ìª½ ì‚°ì ë„
    sb.scatterplot(x=x_left, y=y_left, label='data', ax=axmain)

    # ì™¼ìª½ ì¶”ì„¸ì„ 
    x, y = getTrend(x_left, y_left)
    sb.lineplot(x=x, y=y, color='blue', linestyle='--', ax=axmain)

    # ì™¼ìª½ ì¶”ì •ì¹˜
    if y_left_pred is not None:
        sb.scatterplot(x=x_left, y=y_left_pred, label='predict', ax=axmain)
        # ì¶”ì •ì¹˜ì— ëŒ€í•œ ì¶”ì„¸ì„ 
        x,y = getTrend(x_left, y_left_pred)
        sb.lineplot(x=x, y=y, color='red', linestyle='--', ax=axmain)

    if left_title is not None:
        axmain.set_title(left_title)

    axmain.legend()
    axmain.grid()

    if x_right is not None:
        # ì˜¤ë¥¸ìª½ ì‚°ì ë„
        sb.scatterplot(x=x_right, y=y_right, label='data', ax=ax[1])
        
        # ì˜¤ë¥¸ìª½ ì¶”ì„¸ì„ 
        x, y = getTrend(x_right, y_right)
        sb.lineplot(x=x, y=y, color='blue', linestyle="--", ax=ax[1])
    
        # ì˜¤ë¥¸ìª½ ì¶”ì •ì¹˜
        if y_right_pred is not None:
            sb.scatterplot(x=x_right, y=y_right_pred, label='predict', ax=ax[1])
            # ì¶”ì •ì¹˜ì— ëŒ€í•œ ì¶”ì„¸ì„ 
            x, y = getTrend(x_right, y_right_pred)
            sb.lineplot(x=x, y=y, color='red', linestyle="--", ax=ax[1])
        
        if right_title is not None:
            ax[1].set_title(right_title)
            
        ax[1].legend()
        ax[1].grid()
    
    if save_path is not None:
        plt.savefig(save_path, dpi=300)
        
    plt.show()
    plt.close()


# ë¨¸ì‹ ëŸ¬ë‹(íšŒê·€ë¶„ì„-ì§€ë„í•™ìŠµ)
'''
class OlsResult ê°±ì‹ , class RegMetric ì¶”ê°€
ml_ols ëª¨ë“ˆ ì„¤ëª…
xnamesì— ë…ë¦½ë³€ìˆ˜ ì´ë¦„(ë“¤) ì…ë ¥- list, ë¬¸ìì—´
ynameì— ì¢…ì†ë³€ìˆ˜ ì´ë¦„
degreeë¡œ ì°¨ìˆ˜(1-ë‹¨ìˆœì„ í˜•íšŒê·€, 2-ë‹¤í•­íšŒê·€)
test_sizeë¡œ ë°ì´í„° ë¶„í• (train/test)
random_stateë¡œ í•™ìŠµ ë°ì´í„° ì¡°í•© ì„¤ì • ê°€ëŠ¥(ë°ì´í„° ë¶„í•  ê³ ì •)
'''
def ml_ols(data, xnames, yname, degree=1, test_size=0.25, use_scalling=False, random_state=777):
    # í‘œì¤€í™” ì„¤ì •ì´ ë˜ì–´ ìˆë‹¤ë©´ í‘œì¤€í™” ìˆ˜í–‰
    if scalling:
        data = scalling(data)

    # ë…ë¦½ë³€ìˆ˜ ì´ë¦„ì´ ë¬¸ìì—´ë¡œ ì „ë‹¬ë˜ì—ˆë‹¤ë©´ ì½¤ë§ˆ ë‹¨ìœ„ë¡œ ì˜ë¼ì„œ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    # ë„ì–´ì“°ê¸° ê¸ˆì§€ ex) xnames="ê¸¸ì´,ë†’ì´,ë‘ê»˜" -> True / xnames="ê¸¸ì´, ë†’ì´, ë‘ê»˜" -> False
    if type(xnames) == str:
        xnames = xnames.split(',')

    # ë…ë¦½ë³€ìˆ˜ ì¶”ì¶œ
    x = data.filter(xnames)

    # ì¢…ì†ë³€ìˆ˜ ì¶”ì¶œ - 1ì°¨ì› y = data.filter([yname])ì€ 2ì°¨ì› DF í˜•íƒœ
    y = data[yname]

    # 2ì°¨ì‹ ì´ìƒìœ¼ë¡œ ì„¤ì¢…ëœ ê²½ìš° ì°¨ìˆ˜ì— ë§ê²Œ ë³€í™˜
    if degree > 1:
        x = convertPoly(x, degree=degree)

    # ë°ì´í„° ë¶„í•  ë¹„ìœ¨ì´ 0ë³´ë‹¤ í¬ë©´ ë¶„í•  ìˆ˜í–‰
    if test_size > 0:
        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, random_state=random_state)
    else:
        x_train = x
        y_train = y
        x_test = None
        y_test = None

    # íšŒê·€ë¶„ì„ ìˆ˜í–‰
    model = LinearRegression()
    fit = model.fit(x_train, y_train)

    result = OlsResult()
    result.model = model
    result.fit = fit
    result.coef = fit.coef_ #ê³„ìˆ˜
    result.intercept = fit.intercept_   #ì ˆí¸

    result.x_train = x_train.copy()
    result.y_train = y_train.copy()
    result.train_pred = result.fit.predict(result.x_train)

    if x_test is not None and y_test is not None:
        result.x_test = x_test.copy()
        result.y_test = y_test.copy()
        result.test_pred = result.fit.predict(result.x_test)
        result.setRegMetric(y_train, result.train_pred, y_test, result.test_pred)
    else:
        result.setRegMetric(y_train, result.train_pred)

    # ê²°ê³¼í‘œ í•¨ìˆ˜ í˜¸ì¶œ
    x_train[yname] = y_train
    result.table = get_ols_table(x_train, xnames, yname, result.intercept, result.coef, result.train_pred)

    return result


# ì˜ˆì¸¡ê°’ì„ ìœ„í•œ predict
def get_ols_table(data, xnames, yname, intercept, coef, predict):
    # ë…ë¦½ë³€ìˆ˜ ì´ë¦„ì´ ë¬¸ìì—´ë¡œ ì „ë‹¬ë˜ë©´ ì½¤ë§ˆ ë‹¨ìœ„ë¡œ ì˜ë¼ì„œ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™”
    # # ë„ì–´ì“°ê¸° ê¸ˆì§€ ex) xnames="ê¸¸ì´,ë†’ì´,ë‘ê»˜" -> True / xnames="ê¸¸ì´, ë†’ì´, ë‘ê»˜" -> False
    if type(xnames) == str:
        xnames = xnames.split(',')

    # ë…ë¦½ë³€ìˆ˜ ì¶”ì¶œ
    x = data.filter(xnames)

    # ì¢…ì†ë³€ìˆ˜ ì¶”ì¶œ - 1ì°¨ì› y = data.filter([yname])ì€ 2ì°¨ì› DF í˜•íƒœ
    y = data[yname]

    # ì ˆí¸ê³¼ ê³„ìˆ˜ë¥¼ í•˜ë‚˜ì˜ ë°°ì—´ë¡œ ê²°í•©
    params = np.append(intercept, coef)

    # ìƒìˆ˜í•­ ì¶”ê°€
    designX = x.copy()
    designX.insert(0, 'ìƒìˆ˜', 1)

    # í–‰ë ¬ê³± êµ¬í•˜ê¸°
    dot = np.dot(designX.T,designX)

    # í–‰ë ¬ê³±ì— ëŒ€í•œ ì—­í–‰ë ¬
    inv = np.linalg.inv(dot)

    # ì—­í–‰ë ¬ì˜ ëŒ€ê°ì„  ë°˜í™˜
    dia = inv.diagonal()

    # í‰ê·  ì œê³±ì˜¤ì°¨
    MSE = (sum((y-predict)**2)) / (len(designX)-len(designX.iloc[0]))

    # í‘œì¤€ì˜¤ì°¨
    se_b = np.sqrt(MSE * dia)

    # t ê°’
    ts_b = params / se_b

    # pê°’
    p_values = [2*(1-stats.t.cdf(np.abs(i),(len(designX)-len(designX.iloc[0])))) for i in ts_b]
    
    # VIF
    vif = []

    # í›ˆë ¨ë°ì´í„°ì— ëŒ€í•œ ë…ë¦½/ì¢…ì†ë³€ìˆ˜ë¥¼ ê²°í•©í•œ ì™„ì „í•œ DF ì¤€ë¹„
    data = x.copy()
    data[yname] = y
    # print(data)
    # print("-"*50)

    # ë‹¤ì¤‘ ê³µì„ ì„± ê³„ì‚°ì„ ìœ„í•œ VIF ìƒì„± 
    for i, v in enumerate(x.columns):
        j = list(data.columns).index(v) #í–‰ì˜ index ì •ë³´ ì¶”ì¶œ
        vif.append(variance_inflation_factor(data, j))  #VIFë¥¼ ê³„ì‚°í•˜ê³ , vif ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€

    # ê²°ê³¼í‘œ êµ¬ì„±
    table = DataFrame({
        "ì¢…ì†ë³€ìˆ˜": [yname] * len(x.columns),
        "ë…ë¦½ë³€ìˆ˜": x.columns,
        "B": coef,
        "í‘œì¤€ì˜¤ì°¨": se_b[1:],
        "Î²": 0,
        "t": ts_b[1:],
        "ìœ ì˜í™•ë¥ ": p_values[1:],
        "VIF": vif,
    })

    return table


# ì„ í˜•íšŒê·€ ëª¨ë¸ì˜ ë‹¤í•­íšŒê·€ ëª¨ë¸í™” - sklearnì˜ PolynomialFeatures
# í›ˆë ¨/ê²€ì¦ ë°ì´í„°ì˜ ì†ì‹¤ë¥ , ì ˆëŒ€ì˜¤ì°¨ ê·¸ë˜í”„ ì‹œê°í™”
def tf_result_plot(result, figsize=(15, 5), dpi=150):
    # í•™ìŠµ ê²°ê³¼ì— ëŒ€í•œ DF ìƒì„±
    result_df = DataFrame(result.history)
    result_df['epochs'] = result_df.index+1
    result_df.set_index('epochs', inplace=True)

    # í•™ìŠµ ê²°ê³¼ ê·¸ë˜í”„ì˜ ì»¬ëŸ¼ ëª…
    column_names = result_df.columns

    # í•™ìŠµë°ì´í„°ì— ëŒ€í•œ í•„ë“œì´ë¦„
    train_column_name = [column_names[0], column_names[1]]

    # ê²€ì¦ë°ì´í„°ì— ëŒ€í•œ í•„ë“œì´ë¦„
    test_column_name = [column_names[2], column_names[3]]

    # í•™ìŠµ ê²°ê³¼ ê·¸ë˜í”„

    # # ê·¸ë˜í”„ ê°ì²´ ìƒì„±
    fig, ax = plt.subplots(1,2, figsize=figsize, dpi=dpi)

    # # í›ˆë ¨ ë° ê²€ì¦ ë°ì´í„°ì˜ ì†ì‹¤ë¥ , ì ˆëŒ€ì˜¤ì°¨ ê·¸ë˜í”„ ê·¸ë¦¬ê¸°
    for i, v in enumerate(ax):
        sb.lineplot(x=result_df.index, y=train_column_name[i], data=result_df, color='blue', label=train_column_name[i], ax=v)
        sb.lineplot(x=result_df.index, y=test_column_name[i], data=result_df, color='orange', label=test_column_name[i], ax=v)
        v.set_title(train_column_name[i])
        v.set_xlabel('ephocs')
        v.set_ylabel(train_column_name[i])
        v.grid()
        v.legend()
        
    plt.show()
    plt.close()

    return result_df


# ë¡œì§€ìŠ¤í‹± íšŒê·€ ê²°ê³¼ ê²€ì •
def tf_logit_result(model, fit, x, y):    
    # ì˜ˆì¸¡ê°’ ìƒì„±
    pred_bool = model.predict(x).flatten() > 0.5
    pred = pred_bool.astype(int)
    
    # í˜¼ë™í–‰ë ¬
    cm = confusion_matrix(y, pred)
    tn, fp, fn, tp = cm.ravel()
    cmdf = DataFrame([[tn, fn], [fp, tp]], index=['True', 'False'], columns=['Negative', 'Positive'])

    # RAS
    ras = roc_auc_score(y, pred)

    # ìœ„ì–‘ì„±ìœ¨, ì¬í˜„ìœ¨, ì„ê³„ê°’(ì‚¬ìš©ì•ˆí•¨)
    fpr, tpr, thresholds = roc_curve(y, pred)

    # ì •í™•ë„
    acc = accuracy_score(y, pred)

    # ì •ë°€ë„
    pre = precision_score(y, pred)

    # ì¬í˜„ìœ¨
    recall = recall_score(y, pred)

    # F1 score
    f1 = f1_score(y, pred)

    # ìœ„ì–‘ì„±ìœ¨
    fallout = fp / (fp + tn)

    # íŠ¹ì´ì„±
    spe = 1 - fallout

    result_df = DataFrame({'ì •í™•ë„(Accuracy)':[acc], 'ì •ë°€ë„(Precision)':[pre], 'ì¬í˜„ìœ¨(Recall, TPR)':[recall], 'ìœ„ì–‘ì„±ìœ¨(Fallout, FPR)': [fallout], 'íŠ¹ì´ì„±(Specificity, TNR)':[spe], 'RAS': [ras], 'f1_score':[f1]})

    # ëª¨ë¸ ê°€ì¤‘ì¹˜ì™€ í¸í–¥ ì–»ê¸°
    weights, bias = model.layers[1].get_weights()
    
    # ì˜¤ì¦ˆë¹„ ê³„ì‚°
    odds_ratio = np.exp(weights[0])

    logit_result = LogitResult()
    logit_result.model = model
    logit_result.fit = fit
    logit_result.summary = model.summary()
    #logit_result.prs = prs
    logit_result.cmdf = cmdf
    logit_result.result_df = result_df
    logit_result.odds_rate_df = odds_ratio
    
    return logit_result


'''
ëª¨ë“ˆì„¤ëª…
- ë°ì´í„°ë¥¼ í•™ìŠµí•˜ê³  ì„±ëŠ¥ì„ í‰ê°€
- ëª¨ë¸ì˜ ì„±ëŠ¥ì„ êµì°¨ ê²€ì¦ì„ í†µí•´ ì•ˆì •ì ìœ¼ë¡œ ì¸¡ì •
- ê²°ê³¼ë¥¼ ë¶„ì„ ë° ì‹œê°í™”
> ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€
F. ë°ì´í„° ë§ˆì´ë‹\02. Sklearn\ëª¨ë“ˆí™”.ipynb ì°¸ê³ 
'''
# MLì„±ëŠ¥1
# **kargs: ë‹¤ì–‘í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„°(ì˜µì…˜)ë“¤ì„ ë°›ì„ ìˆ˜ ìˆëŠ” ê°€ë³€ ì¸ì
def singleML(modelName, x, y=None, cv=5, **kargs):
    # ëª¨ë¸ ìƒì„±
    model = modelName(**kargs)
    # êµì°¨ ê²€ì¦
    score = cross_val_score(model, x, y, cv=cv).mean()
    # ê²°ê³¼ DF
    df = DataFrame(cross_validate(model, x, y, cv=cv))
    return [model, score, df]

'''
ë‘ ë²ˆì§¸ ëª¨ë“ˆ
GridSearchCV : ë¨¸ì‹ ëŸ¬ë‹ì—ì„œ ëª¨ë¸ì˜ ì„±ëŠ¥í–¥ìƒì„ ìœ„í•´ ì“°ì´ëŠ” ê¸°ë²•ì¤‘ í•˜ë‚˜. 
ì‚¬ìš©ìê°€ ì§ì ‘ ëª¨ë¸ì˜ í•˜ì´í¼ íŒŒë¼ë¯¸í„°ì˜ ê°’ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ì…ë ¥í•˜ë©´ 
ê°’ì— ëŒ€í•œ ê²½ìš°ì˜ ìˆ˜ë§ˆë‹¤ ì˜ˆì¸¡ ì„±ëŠ¥ì„ ì¸¡ì • í‰ê°€/ë¹„êµí•˜ë©´ì„œ 
ìµœì ì˜ í•˜ì´í¼ íŒŒë¼ë¯¸í„° ê°’ì„ ì°¾ëŠ” ê³¼ì •ì„ ì§„í–‰.
'''
# # MLì„±ëŠ¥2
# **kargs: ë‹¤ì–‘í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„°(ì˜µì…˜)ë“¤ì„ ë°›ì„ ìˆ˜ ìˆëŠ” ê°€ë³€ ì¸ì
def gridML(modelName, x, y=None, params={}, cv=5, **kargs):
    # ëª¨ë¸ ìƒì„±
    model = modelName(**kargs)
    # grid ìƒì„±
    grid = GridSearchCV(model, param_grid=params, cv=cv)

    try:
        grid.fit(x,y)   # ì§€ë„í•™ìŠµ
    except:
        grid.fit(x) # ë¹„ì§€ë„í•™ìŠµ

    result_df = DataFrame(grid.cv_results_["params"])
    result_df['mean_test_score'] = grid.cv_results_['mean_test_score']
    result_df.sort_values(by='mean_test_score', ascending=False)
    
    return [grid.best_estimator_, grid.best_score_, result_df]

